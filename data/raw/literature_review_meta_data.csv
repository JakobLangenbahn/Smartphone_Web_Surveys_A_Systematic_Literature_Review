"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"FB2WDXXG","journalArticle","2017","Revilla, Melanie; Toninelli, Daniele; Ochoa, Carlos","An experiment comparing grids and item-by-item formats in web surveys completed through PCs and smartphones.","Telematics & Informatics","","","","http://www.redi-bw.de/db/ebsco.php/search.ebscohost.com/login.aspx%3fdirect%3dtrue%26db%3dufh%26AN%3d117440989%26site%3dehost-live","Some respondents already complete web surveys via mobile devices. These devices vary at several levels from PCs. In particular, we expect differences when grid questions are used due to the lower visibility on mobile devices and because in questionnaires optimized to be completed through smartphones, grids are split up into an item-by-item format. This paper reports the results of a two-wave experiment conducted in Spain in 2015, comparing three groups: PCs, smartphones not-optimized, or smartphones optimized. We found similar levels of interitem correlations, longer completion times for grid questions for smartphone respondents, and sometimes less non-differentiation for PCs. Thus, using the item-by-item format for smartphones and PCs seems the most appropriate way to improve comparability. [ABSTRACT FROM AUTHOR]","2017","2022-01-08 12:52:53","2022-01-08 12:52:53","","30-42","","1","34","","","","","","","","","","","","","","","","","","","","","Smartphones; Mobile communication systems; Completion time; Personal computers; Web surveys; Comparative studies; Grids; Interitem correlation; Non-differentiation; Internet surveys; Grid computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8WD8IYY","journalArticle","2019","Bosch, Oriol J.; Revilla, Melanie; Paura, Ezequiel","Answering Mobile Surveys With Images: An Exploration Using a Computer Vision API","Social Science Computer Review","","","10.1177/0894439318791515","https://doi.org/10.1177/0894439318791515","Most mobile devices nowadays have a camera. Besides, posting and sharing images have been found as one of the most frequent and engaging Internet activities. However, to our knowledge, no research has explored the feasibility of asking respondents of online surveys to upload images to answer survey questions. The main goal of this article is to investigate the viability of asking respondents of an online opt-in panel to upload during a mobile web survey: First, a photo taken in the moment, and second, an image already saved on their smartphone. In addition, we want to test to what extent the Google Vision application programming interface (API), which can label images into categories, produces similar tags than a human coder. Overall, results from a survey conducted among millennials in Spain and Mexico (N = 1,614) show that more than half of the respondents uploaded an image. Of those, 77.3% and 83.4%, respectively, complied with what the question asked. Moreover, respectively, 52.4% and 65.0% of the images were similarly codified by the Google Vision API and the human coder. In addition, the API codified 1,818 images in less than 5 min, whereas the human coder spent nearly 35 hours to complete the same task.","2019","2022-01-08 12:52:53","2022-01-08 12:52:53","","669-683","","5","37","","","","","","","","","","","","","","","","","","","","","Mobile Devices; computer vision; Cameras; Computer vision; Internet; Smartphones; Education--Computer Applications; Electronic devices; mobile web survey; Polls & surveys; Questions; API; Computers; image recognition; new data types; Online Surveys; smartphone; COMMUNICATION; Millennials; MILLENNIALS; PHOTO; Photography; Application programming interface; Codification; Images; Viability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C86P62FD","journalArticle","2019","Ha, Louisa,; Zhang, Chenjie","Are computers better than smartphones for web survey responses?","Online Information Review","","","10.1108/OIR-11-2017-0322","","Purpose The purpose of this paper is to examine the effect of smartphones and computers as web survey entry response devices on the quality of responses in different question formats and across different survey invitations delivery modes. The respondents' preference of device and the response immediacy were also compared. Design/methodology/approach Two field experiments were conducted with a cluster sampling and a census of all students in a public university in the USA. Findings Device effect on response quality was only found when using computer-aided self-interviews, but not in e-mail delivered web surveys. Even though the computer was the preferred device, but the smartphone's immediate response was significantly higher than the computer. Research limitations/implications The sample was restricted to college students who are more proficient users of smartphones and have high access to computers. But the direct comparison in the two studies using the same population increases the internal validity of the study comparing different web survey delivery modes. Practical implications Because of the minor differences in device on response quality, researchers can consider using more smartphones for field work such as computer-aided self-interviews to complement e-mail delivered surveys. Originality/value This is the first study that compares the response device effects of computer-aided self-interviews and e-mailed delivered web surveys. Because web surveys are increasingly used and various devices are being used to collect data, how respondents behave in different devices and the strengths and weaknesses of different methods of delivery survey help researchers to improve data quality and develop effective web survey delivery and participant recruitment.","2019","2022-01-08 12:52:53","2022-01-08 12:52:53","","350-368","","3","43","","","","","","","","","","","","","","","","","","","","","Smartphones; QUALITY; DESIGN; MOBILE; PC WEB; MODES; Computer-aided self-interviews; DATA-COLLECTION; Mobile survey; Survey response quality; Web survey","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNVQ5GQP","journalArticle","2015","Buskirk, Trent D.","Are sliders too slick for surveys? An experiment comparing slider and radio button scales for smartphone, tablet and computer based surveys","methods, data, analyses","","","","https://www.wiso-net.de/document/MDA__45666","""The continued rise in smartphone penetration globally afford survey researchers with an unprecedented portal into personal survey data collection from respondents who could complete surveys from virtually any place at any time. While the basic research into optimizing the survey experience and data collection on mobile devices has continued to develop, there are still fundamental gaps in our knowledge of how to optimize certain types of questions in the mobile setting. In fact, survey researchers are still trying to understand which online design principles directly translate into presentation on mobile devices and which principles have to be modified to incorporate separate methods for these devices. One such area involves the use of input styles such as sliding scales that lend themselves to more touch centric input devices such as smartphones or tablets. Operationalizing these types of scales begs the question of an optimal starting position and whether these touch centric input styles are equally preferred by respondents using less touch capable devices. While an outside starting position seems optimal for slider questions completed via computer, this solution may not be optimal for completion via mobile devices as these devices are subjected to far more space and layout constraints compared to computers. This experiment moves the mixed device survey literature forward by directly comparing outcomes from respondents who completed a collection of survey scales using their smartphone, tablet or computer. Within each device, respondents were randomly assigned to complete one of 20 possible versions of scale items determined by a combination of three experimental factors including input style, length and number formatting. Results from this study suggest more weaknesses than strengths for using slider scales to collect survey data using mobile devices and also suggest that preference for these touch centric input styles varies across devices and may not be as high as the preference for the more traditional radio button style."" (author's abstract)","2015","2022-01-08 12:52:53","2022-01-08 12:52:53","","229-260","","2","9","","","","","","","","","","","","","","","","","","","","","Mobiltelefon; Datengewinnung; Antwortverhalten; data capture; online survey; Online-Befragung; response behavior; survey research; Umfrageforschung; Datenqualität; data quality; cell phone; computer; Computer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZIMNSLF","journalArticle","2017","Revilla, Melanie","Are There Differences Depending on the Device Used to Complete a Web Survey (PC or Smartphone) for Order-by-click Questions?","Field methods","","","10.1177/1525822X16674701","https://doi.org/10.1177/1525822X16674701","The development of web surveys has been accompanied by the emergence of new scales, taking advantages of the visual and interactive features provided by the Internet like drop-down menus, sliders, drag-and-drop, or order-by-click scales. This article focuses on the order-by-click scales, studying the comparability of the data obtained for this scale when answered through PCs versus smartphones. I used data from an experiment where panelists from the Netquest opt-in panel in Spain were randomly assigned to a PC, smartphone optimized, or smartphone not-optimized version of the same questionnaire in two waves. I found significant differences due to the device and optimization at least for some indicators and questions.","2017","2022-01-08 12:52:53","2022-01-08 12:52:53","","266-280","","3","29","","","","","","","","","","","","","","","","","","","","","Internet; Smartphones; smartphones; Polls & surveys; Research responses; Questionnaires; Mobile Phones; Surveys; Websites; MOBILE; web surveys; Anthropology; Microcomputers; COMPUTER; PANELS; PC; social anthropology; 0514:culture and social structure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QTXHS9D2","journalArticle","2019","Haan, Marieke; Lugtig, Peter; Toepoel, Vera","Can we predict device use? An investigation into mobile device use in surveys","International Journal of Social Research Methodology","","","10.1080/13645579.2019.1593340","","In this study, we investigate whether mobile device use in surveys can be predicted. We aim to identify possible motives for device use and build a model by drawing on theory from technology acceptance research and survey research. We then test this model with a Structural Equation Modeling approach using data of seven waves of the GESIS panel. We test whether our theoretical model fits the data by focusing on measures of fit, and by studying the standardized effects of the model. Results reveal that intention to use a particular device can predict actual use quite well. Ease of smartphone use is the most meaningful variable: if people use a smartphone for specific tasks, their intention to use a smartphone for survey completion is also more likely. In conclusion, investing in ease of use of mobile survey completion could encourage respondents to use mobile devices. This can foremost be established by building well-designed surveys for mobile devices.","2019","2022-01-08 12:52:53","2022-01-08 12:52:53","","517-531","","5","22","","","","","","","","","","","","","","","","","","","","","ACCEPTANCE; TECHNOLOGY; technology acceptance; WEB; mixed device; Mobile device use; ONLINE SURVEYS; panel survey","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGLVAJJA","journalArticle","2019","Erens, Bob; Manacorda, Tommaso; Gosling, Jennifer; Mays, Nicholas; Reid, David; Taylor, William","Comparing data quality from personal computers and mobile devices in an online survey among professionals Funding acknowledgement","Social Research Practice","","","","www.qualtrics.com","It is increasingly common for respondents to complete web surveys using mobile devices (smartphones and tablets) rather than personal computers/laptops (PCs). Evidence of the impact of the use of mobile devices on response and data quality shows mixed results and is only available for general population surveys. We looked at response quality for a work-related survey in the UK among general practitioners (GPs). GPs were sent email invitations to complete a web survey and half (55%) completed it on a mobile device. While GPs using a mobile device were less likely to complete the full questionnaire than those using a PC, we found no differences in data quality between mobile and PC users, except for PC users being more likely to respond to open-ended questions.","2019","2022-01-08 12:52:53","2022-01-08 12:52:53","","15-26","","","7","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSQR9RUS","journalArticle","2018","Revilla, Melanie; Couper, Mick P.","Comparing Grids With Vertical and Horizontal Item-by-Item Formats for PCs and Smartphones","Social Science Computer Review","","","10.1177/0894439317715626","https://doi.org/10.1177/0894439317715626","Much research has been done comparing grids and item-by-item formats. However, the results are mixed, and more research is needed especially when a significant proportion of respondents answer using smartphones. In this study, we implemented an experiment with seven groups (n = 1,476), varying the device used (PC or smartphone), the presentation of the questions (grids, item-by-item vertical, item-by-item horizontal), and, in the case of smartphones only, the visibility of the ?next? button (always visible or only visible at the end of the page, after scrolling down). The survey was conducted by the Netquest online fieldwork company in Spain in 2016. We examined several outcomes for three sets of questions, which are related to respondent behavior (completion time, lost focus, answer changes, and screen orientation) and data quality (item missing data, nonsubstantive responses, instructional manipulation check failure, and nondifferentiation). The most striking difference found is for the placement of the next button in the smartphone item-by-item conditions: When the button is always visible, item missing data are substantially higher.","2018","2022-01-08 12:52:53","2022-01-08 12:52:53","","349-368","","3","36","","","","","","","","","","","","","","","","","","","","","Technology; Visibility; Internet; Smartphones; Education--Computer Applications; smartphones; Telephone communications; data quality; Data quality; Mobile Phones; DESIGN; web surveys; Microcomputers; Product Design; Human Factors Engineering; WEB SURVEYS; Completion time; PARADATA; Missing data; Scrolling; grids; item-by-item; respondent behavior; scale orientation; LAYOUT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5UQQVKE","journalArticle","2013","De Bruijne, Marika; Wijnant, Arnaud","Comparing Survey Results Obtained via Mobile Devices and Computers: An Experiment With a Mobile Web Survey on a Heterogeneous Group of Mobile Devices Versus a Computer-Assisted Web Survey","Social Science Computer Review","","","10.1177/0894439313483976","https://doi.org/10.1177/0894439313483976","With the growing popularity of smartphones and tablet PCs (tablets) equipped with mobile browsers, the possibilities to administer surveys via mobile devices have expanded. To investigate the possible mode effect on answer behavior, results are compared between a mobile device?assisted web survey and a computer-assisted web survey. First, a premeasurement in the CentERpanel is conducted to analyze the user group of mobile devices. Second, the users are randomly allocated one of the three conditions: (1) conventional computer-assisted web survey, (2) hybrid version: a computer-assisted web survey with a layout similar to mobile web survey, and (3) mobile web survey. Special attention is given to the design of the mobile web questionnaire, taking small screen size, and typical functionalities for touchscreens into account. The findings suggest that survey completion on mobile devices need not lead to different results than on computers, but one should be prepared for a lower response rate and longer survey completion time. Further, the study offers considerations for researchers on survey satisfaction, location during survey completion, and preferred device to access Internet. With adaptations, surveys can be conducted on the newest mobile devices, although new challenges are emerging and further research is called for.","2013","2022-01-08 12:52:53","2022-01-08 12:52:53","","482-504","","4","31","","","","","","","","","","","","","","","","","","","","","Heterogeneity; Portable computers; Internet; Smartphones; Education--Computer Applications; smartphones; mobile web survey; Polls & surveys; Satisfaction; mobile devices; Mobile Phones; Surveys; Computers; Attention; computer web survey; mobile device; Popularity; research surveys; response rate; special attention; INTERPRETIVE HEURISTICS; SEARCH; Access; SURVEY DESIGN; Response rates; Comparative studies; computer methods, media, & applications; OPTIMAL NUMBER; RATING-SCALES; survey design; tablet PCs; touch user interfaces; 0188: methodology and research technology; article; mobile web survey smartphones tablet PCs mobile devices survey design touch user interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"92WGWQCX","journalArticle","2014","Wells, Tom; Bailey, Justin T.; Link, Michael W.","Comparison of Smartphone and Online Computer Survey Administration","Social Science Computer Review","","","10.1177/0894439313505829","https://doi.org/10.1177/0894439313505829","The dramatic rise of smartphones has profound implications for survey research. Namely, can smartphones become a viable and comparable device for self-administered surveys? The current study is based on approximately 1,500 online U.S. panelists who were smartphone users and who were randomly assigned to the mobile app or online computer mode of a survey. Within the survey, we embedded several experiments that had been previously tested in other modes (mail, PC web, mobile web). First, we test whether responses in the mobile app survey are sensitive to particular experimental manipulations as they are in other modes. Second, we test whether responses collected in the mobile app survey are similar to those collected in the online computer survey. Our mobile survey experiments show that mobile survey responses are sensitive to the presentation of frequency scales and the size of open-ended text boxes, as are responses in other survey modes. Examining responses across modes, we find very limited evidence for mode effects between mobile app and PC web survey administrations. This may open the possibility for multimode (mobile and online computer) surveys, assuming that certain survey design recommendations for mobile surveys are used consistently in both modes.","2014","2022-01-08 12:52:53","2022-01-08 12:52:53","","238-255","","2","32","","","","","","","","","","","","","","","","","","","","","Mobile Devices; Internet; Smartphones; Education--Computer Applications; smartphones; Polls & surveys; computers; United States--US; Human Computer Interaction; Mobile Phones; Surveys; Human Machine Systems Design; Computers; Software; Websites; mobile surveys; test administration format; Test Forms; text boxes; Text Structure; websites; online surveys; RESPONSES; MAIL; MOBILE WEB SURVEY; OPEN-ENDED QUESTIONS; ORDER; experiments; computer methods, media, & applications; 0188: methodology and research technology; article; mobile surveys online surveys smartphones experiments; Users","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQCN99HI","journalArticle","2021","Weigold, Arne; Weigold, Ingrid K.; Dykema, Stephanie A.; Drakeford, Naomi M.; Martin-Wagar, Caitlin A.","Computerized Device Equivalence: A Comparison of Surveys Completed Using A Smartphone, Tablet, Desktop Computer, and Paper-and-Pencil","International Journal of Human-Computer Interaction","","","10.1080/10447318.2020.1848159","","There is a limited body of experimental research examining the comparability of completing self-report surveys using different computerized devices. Additionally, available literature has not used complete or optimal procedures for determining device equivalence. The current study examined the comparability of surveys completed using paper-and-pencil and three popular devices: smartphone, tablet, and desktop computer. Participants consisted of 211 college students randomly assigned to conditions who completed measures of personality, social desirability, and computer self-efficacy. Results showed evidence of qualitative equivalence (internal consistency and subscale intercorrelations) across conditions. For quantitative and auxiliary equivalence, both equivalence testing and Bayesian analyses were conducted. Equivalence testing indicated quantitative (mean score) equivalence, as well as comparability for one aspect of auxiliary equivalence (missing data). Other aspects of auxiliary equivalence (completion time and comfort completing questionnaires) suggested potentially meaningful differences. Bayesian analyses typically replicated these results, with some notable exceptions regarding auxiliary equivalence.","2021","2022-01-08 12:52:53","2022-01-08 12:52:53","","803-814","","8","37","","","","","","","","","","","","","","","","","","","","","VALIDATION; QUALITY; TECHNOLOGY; INTERNET; MOBILE; SELF-EFFICACY; WEB; SOCIAL DESIRABILITY; SHORT FORMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D9SCQ9EX","journalArticle","2020","Keusch, Florian; Bähr, Sebastian; Haas, Georg-Christoph; Kreuter, Frauke; Trappmann, Mark","Coverage Error in Data Collection Combining Mobile Surveys With Passive Measurement Using Apps: Data From a German National Survey","Sociological Methods & Research","","","10.1177/0049124120914924","https://doi.org/10.1177/0049124120914924","Researchers are combining self-reports from mobile surveys with passive data collection using sensors and apps on smartphones increasingly more often. While smartphones are commonly used in some groups of individuals, smartphone penetration is significantly lower in other groups. In addition, different operating systems (OSs) limit how mobile data can be collected passively. These limitations cause concern about coverage error in studies targeting the general population. Based on data from the Panel Study Labour Market and Social Security (PASS), an annual probability-based mixed-mode survey on the labor market and poverty in Germany, we find that smartphone ownership and ownership of smartphones with specific OSs are correlated with a number of sociodemographic and substantive variables. The use of weighting techniques based on sociodemographic information available for both owners and nonowners reduces these differences but does not eliminate them.","2020","2022-01-08 12:52:53","2022-01-08 12:52:53","","","","","","","","","","","","","","","","","","","","","","","","","","smartphones; mobile web surveys; passive mobile data collection; coverage error; operating systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G745XGA9","journalArticle","2020","Ha, Louisa,; Zhang, Chenjie; Jiang, Weiwei","Data quality comparison between computers and smartphones in different web survey modes and question formats","Internet Research","","","10.1108/INTR-09-2018-0417","","Purpose Low response rates in web surveys and the use of different devices in entering web survey responses are the two main challenges to response quality of web surveys. The purpose of this study is to compare the effects of using interviewers to recruit participants in computer-assisted self-administered interviews (CASI) vs computer-assisted personal interviews (CAPI) and smartphones vs computers on participation rate and web survey response quality. Design/methodology/approach Two field experiments using two similar media use studies on US college students were conducted to compare response quality in different survey modes and response devices. Findings Response quality of computer entry was better than smartphone entry in both studies for open-ended and closed-ended question formats. Device effect was only significant on overall completion rate when interviewers were present. Practical implications Survey researchers are given guidance how to conduct online surveys using different devices and choice of question format to maximize survey response quality. The benefits and limitations of using an interviewer to recruit participants and smartphones as web survey response devices are discussed. Social implications It shows how computer-assisted self-interviews and smartphones can improve response quality and participation for underprivileged groups. Originality/value This is the first study to compare response quality in different question formats between CASI, e-mailed delivered online surveys and CAPI. It demonstrates the importance of human factor in creating sense of obligation to improve response quality.","2020","2022-01-08 12:52:53","2022-01-08 12:52:53","","1763-1781","","6","30","","","","","","","","","","","","","","","","","","","","","Smartphone; Data quality; DESIGN; FACE-TO-FACE; MAIL; INDICATORS; ONLINE SURVEYS; NONRESPONSE; Computer-assisted personal Interview; Computer-assisted self-interview; Interviewer; Survey mode","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HXDD5MK","journalArticle","2013","Mavletova, Aigul","Data Quality in PC and Mobile Web Surveys","Social Science Computer Review","","","10.1177/0894439313485201","https://doi.org/10.1177/0894439313485201","The considerable growth in the number of smart mobile devices with a fast Internet connection provides new challenges for survey researchers. In this article, I compare the data quality between two survey modes: self-administered web surveys conducted via personal computer and those conducted via mobile phones. Data quality is compared based on five indicators: (a) completion rates, (b) response order effects, (c) social desirability, (d) non-substantive responses, and (e) length of open answers. I hypothesized that mobile web surveys would result in lower completion rates, stronger response order effects, and less elaborate answers to open-ended questions. No difference was expected in the level of reporting in sensitive items and in the rate of non-substantive responses. To test the assumptions, an experiment with two survey modes was conducted using a volunteer online access panel in Russia. As expected, mobile web was associated with a lower completion rate, shorter length of open answers, and similar level of socially undesirable and non-substantive responses. However, no stronger primacy effects in mobile web survey mode were found.","2013","2022-01-08 12:52:53","2022-01-08 12:52:53","","725-743","","6","31","","","","","","","","","","","","","","","","","","","","","Data analysis; Quality; Mobile Devices; Internet; Smartphones; Education--Computer Applications; data quality; Polls & surveys; mobile devices; Internet access; Surveys; mobile web surveys; BIAS; personal computers; web surveys; METAANALYSIS; Microcomputers; social desirability; Data Collection; MODE; NONRESPONSE; Russia; Comparative studies; SENSITIVE QUESTIONS; computer methods, media, & applications; 0188: methodology and research technology; article; Methodology (Data Collection); Data Quality; RESPONSE RATES; Social Desirability; Volunteers; web surveys mobile web surveys data quality completion rates response order effects primacy effects social desirability non-substantive responses length of open-ended questions; completion rates; AUDIO; length of open-ended questions; non-substantive responses; primacy effects; response order effects","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F3ILWKQ5","journalArticle","2018","Antoun, Christopher; Katz, Jonathan; Argueta, Josef; Wang, Lin","Design Heuristics for Effective Smartphone Questionnaires","Social Science Computer Review","","","10.1177/0894439317727072","","Design principles for survey questionnaires viewed on desktop and laptop computers are increasingly being seen as inadequate for the design of questionnaires viewed on smartphones. Insights gained from empirical research can help those conducting mobile surveys to improve their questionnaires. This article reports on a systematic literature review of research presented or published between 2007 and 2016 that evaluated the effect of smartphone questionnaire design features on indicators of response quality. The evidence suggests that survey designers should make efforts to ?optimize? their questionnaires to make them easier to complete on smartphones, fit question content to the width of smartphone screens to prevent horizontal scrolling, and choose simpler types of questions (single-choice questions, multiple-choice questions, text-entry boxes) over more complicated types of questions (large grids, drop boxes, slider questions). Based on these results, we identify design heuristics, or general principles, for creating effective smartphone questionnaires. We distinguish between five of them: readability, ease of selection, visibility across the page, simplicity of design elements, and predictability across devices. They provide an initial framework by which to evaluate smartphone questionnaires, though empirical testing and further refinement of the heuristics is necessary.","2018","2022-01-08 12:52:53","2022-01-08 12:52:53","","557-574","","5","36","","","","","","","","","","","","","","","","","","","","","Literature reviews; Visibility; Smartphones; Education--Computer Applications; Polls & surveys; Questionnaires; QUALITY; Design; mobile web surveys; response quality; COMPUTER; smartphone surveys; PC; Research design; Heuristic; DEVICE AFFECT; MOBILE WEB SURVEY; PANEL; questionnaire design; SCALES; SLIDER; Scrolling; Boxes; Screens","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G9XU4SER","journalArticle","2016","Mavletova, Aigul; Couper, Mick P.","Device use in web surveys: The effect of differential incentives","International Journal of Market Research","","","10.2501/IJMR-2016-034","http://www.redi-bw.de/db/ebsco.php/search.ebscohost.com/login.aspx%3fdirect%3dtrue%26db%3dpsyh%26AN%3d2017-05795-002%26site%3dehost-live","This study should be considered as a preliminary exploration of the effect of differential incentives on participation rates, the proportion of mobile respondents, and sample composition in web surveys. The experiment has some limitations, which should be taken into consideration in subsequent studies. First, the experiment is based on a sample of frequent mobile web users, and the results could be different from a sample of those who use mobile internet less frequently. Second, the experiment is based on a volunteer online access panel and the results could be different in a representative online panel. Third, we tested the differential incentives starting with incentives 50% higher than typical incentives. We suggest that it is worth exploring the effect of other incentives (e.g. 20% or 30% higher). Finally, we suggest that it is worth exploring the difference in participation rates between the conditions in which higher-than-typical incentives would be offered for all participants and when offered only for using a particular device. (PsycINFO Database Record (c) 2018 APA, all rights reserved)","2016","2022-01-08 12:52:53","2022-01-08 12:52:53","","523-544","","4","58","","","","","","","","","","","","","","","","","","","","","Marketing; Mobile Devices; Incentives; Internet; mobile devices; Surveys; market research; web surveys","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQYC2LKS","journalArticle","2017","Mendelson, Jonathan; Gibson, Jennifer L.; Romano-Bergstrom, Jennifer","Displaying Videos in Web Surveys: Implications for Complete Viewing and Survey Responses","Social Science Computer Review","","","10.1177/0894439316662439","https://doi.org/10.1177/0894439316662439","Videos are often used in web surveys to assess attitudes. While including videos may allow researchers to test immediate reactions, there may be issues associated with displaying videos that are overlooked. In this article, we examine the effects of using video stimuli on responses in a probability-based web survey. Specifically, we evaluate the association between demographics, mobile device usage, and the ability to view videos; differences in ad recall based on whether respondents saw a video or still images of the video; whether respondents? complete viewing of videos is related to presentation order; and the data quality of follow-up questions to the videos as a function of presentation order and complete viewing. Overall, we found that respondents using mobile browsers were less likely to be able to view videos in the survey. Those who could view videos were more likely to indicate recall compared to those who viewed images, and videos that were shown later in the survey were viewed in their entirety less frequently than those shown earlier. These results directly pertain to the legitimacy of using videos in web surveys to gather data about attitudes.","2017","2022-01-08 12:52:53","2022-01-08 12:52:53","","654-665","","5","35","","","","","","","","","","","","","","","","","","","","","Mobile Devices; data quality; Test Construction; Surveys; web surveys; advertising; Attitude Measures; Digital Video; measurement; Video Display Units; videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KTE2MFE","journalArticle","2019","Bosch, Oriol J.; Revilla, Melanie; Paura, Ezequiel","Do Millennials differ in terms of survey participation?:","International Journal of Market Research","","","10.1177/1470785318815567","https://journals.sagepub.com/doi/full/10.1177/1470785318815567","Millennials have been the focus of quite some research because of their differences with older cohorts. Besides, young respondents have been considered as a hard target population for surveys. Howe...","2019-12","2022-01-08 12:52:53","2022-01-08 12:52:53","","359-365","","4","61","","","","","","","","","","","","","","","","","Publisher: SAGE PublicationsSage UK: London, England","","","","smartphones; Millennials; survey participation; survey evaluation; break-off","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2LJUQN4L","journalArticle","2016","Revilla, Melanie; Toninelli, Daniele; Ochoa, Carlos; Loewe, Germán","Do online access panels need to adapt surveys for mobile devices?","Internet Research","","","10.1108/IntR-02-2015-0032","","Purpose - Despite the quick spread of the use of mobile devices in survey participation, there is still little knowledge about the potentialities and challenges that arise from this increase. The purpose of this paper is to study how respondents' preferences drive their choice of a certain device when participating in surveys. Furthermore, this paper evaluates the tolerance of participants when specifically asked to use mobile devices and carry out other specific tasks, such as taking photographs. Design/methodology/approach - Data were collected by surveys in Spain, Portugal and Latin America by Netquest, an online fieldwork company. Findings - Netquest panellists still mainly preferred to participate in surveys using personal computers. Nevertheless, the use of tablets and smartphones in surveys showed an increasing trend; more panellists would prefer mobile devices, if the questionnaires were adapted to them. Most respondents were not opposed to the idea of participating in tasks such as taking photographs or sharing GPS information. Research limitations/implications - The research concerns an opt-in online panel that covers a specific area. For probability-based panels and other areas the findings may be different. Practical implications - The findings show that online access panels need to adapt their surveys to mobile devices to satisfy the increasing demand from respondents. This will also allow new, and potentially very interesting data collection methods. Originality/value - This study contributes to survey methodology with updated findings focusing on a currently underexplored area. Furthermore, it provides commercial online panels with useful information to determine their future strategies.","2016","2022-01-08 12:52:53","2022-01-08 12:52:53","","1209-1227","","5","26","","","","","","","","","","","","","","","","","","","","","Survey; Methodology; ADOPTION; World Wide Web; PC; WEB SURVEYS; COMPUTERS; Mobile communications; Netquest; Technological innovation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QD3UVTJX","journalArticle","2019","Hartman, John D.; Craig, Benjamin M.","Does Device or Connection Type Affect Health Preferences in Online Surveys?","The Patient-Patient-Centered Outcomes Research","","","10.1007/s40271-019-00380-z","","Background and Objective Recent evidence has shown that online surveys can reliably collect preference data, which markedly decrease the cost of health preference studies and expand their representativeness. As the use of mobile technology continues to grow, we wanted to examine its potential impact on health preferences. Methods Two recently completed discrete choice experiments using members of the US general population (n = 15,292) included information on respondent device (cell phone, tablet, Mac, PC) and internet connection (business, cellular, college, government, residential). In this analysis, we tested for differences in respondent characteristics, participation, response quality, and utility values for the 5-level EQ-5D (EQ-5D-5L) by device and connection. Results Compared to Mac and PC users, respondents using a cell phone or tablet had longer completion times and were significantly more likely to drop out during the surveys (p < 0.001). Tablet users also demonstrated more logical inconsistencies (p = 0.05). Likewise, respondents using a cellular internet connection exhibit significantly less consistency in their health preferences. However, matched samples for tablets and cell phones produced similar EQ-5D-5L utility values (mean differences < 0.06 on a quality-adjusted life-year [QALY] scale for all potential health states). Conclusion Allowing respondents to complete online surveys using a cell phone or tablet or over a cellular connection substantially increases the diversity of respondents and the likelihood of obtaining a representative sample, as many individuals have cell phones but not a computer. While the results showed systematic variability in participation and response quality by device and connection type, this study did not show any meaningful changes in utility values.","2019","2022-01-08 12:52:53","2022-01-08 12:52:53","","639-650","","6","12","","","","","","","","","","","","","","","","","","","","","PROBABILITY-BASED PANEL; SMARTPHONES; DATA QUALITY; MOBILE WEB; SENSITIVE TOPICS; WEB SURVEYS; DISCRETE-CHOICE EXPERIMENTS; LOGICAL INCONSISTENCIES; PROPENSITY SCORE; STATE VALUATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJXSIANY","journalArticle","2019","Gummer, Tobias; Quoß, Franziska; Roßmann, Joss","Does Increasing Mobile Device Coverage Reduce Heterogeneity in Completing Web Surveys on Smartphones?","Social Science Computer Review","","","10.1177/0894439318766836","https://doi.org/10.1177/0894439318766836","Mobile coverage recently has reached an all-time high, and in most countries, high-speed Internet connections are widely available. Due to technological development, smartphones and tablets have become increasingly popular. Accordingly, we have observed an increasing use of mobile devices to complete web surveys and, hence, survey methodologists have shifted their attention to the challenges that stem from this development. The present study investigated whether the growing use of smartphones has decreased how systematically this choice of device varies between groups of respondents (i.e., how selective smartphone usage for completing web surveys is). We collected a data set of 18,520 respondents from 18 web surveys that were fielded in Germany between 2012 and 2016. Based on these data, we show that while the use of smartphones to complete web surveys has considerably increased over time, selectivity with respect to using this device has remained stable.","2019","2022-01-08 12:52:54","2022-01-08 12:52:54","","371-384","","3","37","","","","","","","","","","","","","","","","","","","","","Mobile Devices; Internet; Smartphones; Education--Computer Applications; smartphones; Electronic devices; Polls & surveys; mobile devices; Surveys; BIAS; smartphone; Mobile communication systems; Tablet computers; web surveys; Choice Behavior; device choice; Microcomputers; PROBABILITY-BASED PANEL; DATA QUALITY; survey error; PC; TABLETS; IMPROVING RESPONSE; selectivity; Technological change; Focus groups; Selectivity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EFTC7PSZ","journalArticle","2015","Liebe, Ulf; Glenk, Klaus; Oehlmann, Malte; Meyerhoff, Jürgen","Does the use of mobile devices (tablets and smartphones) affect survey quality and choice behaviour in web surveys?","Journal of choice modelling","","","10.1016/j.jocm.2015.02.002","","Web surveys are becoming increasingly popular in survey research including stated preference surveys. Compared with face-to-face, telephone and mail surveys, web surveys may contain a different and new source of measurement error and bias: the type of device that respondents use to answer the survey questions. This is the first study that tests whether the use of mobile devices, tablets or smartphones, affects survey characteristics and stated preferences in a web-based choice experiment. The web survey on expanding renewable energy production in Germany was carried out with 3182 respondents, of which 12% used a mobile device. Propensity score matching is used to account for selection bias in the use of mobile devices for survey completion. We find that mobile device users spent more time than desktop/laptop users to answer the survey. Yet, desktop/laptop users and mobile device users do not differ in acquiescence tendency as an indicator of extreme response patterns. For mobile device users only, we find a negative correlation between screen size and interview length and a positive correlation between screen size and acquiescence tendency. In the choice experiment data, we do not find significant differences in the tendency to choose the status quo option and scale between both subsamples. However, some of the estimates of implicit prices differ, albeit not in a unidirectional fashion. Model results for mobile device users indicate a U-shaped relationship between error variance and screen size. Together, the results suggest that using mobile devices is not detrimental to survey quality. (C) 2015 Elsevier Ltd. All rights reserved.","2015","2022-01-08 12:52:54","2022-01-08 12:52:54","","17-31","","","14","","","","","","","","","","","","","","","","","","","","","Smartphone; SCALE; INTERNET; Mobile device; Choice experiment; Renewable energy; FACE-TO-FACE; Propensity score matching; Survey quality; Acquiescence bias; COMPLEXITY; Sample selection bias; Survey format; VALUATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9KB9UYZR","journalArticle","2020","Trübner, Miriam","Effects of Header Images on Different Devices in Web Surveys","Survey Research Methods","","","10.18148/srm/2020.v14i1.7367","","Header images are typically included in web surveys to make surveys more appealing for respondents. However, headers might also induce a systematic bias in response behavior. In order to examine both the potential effects (more specifically, effects on motivation and context effects) of header images with respondents using different devices, an experiment embedded in a web survey on students' time use and stress was conducted using a probability sample of 1,326 students at the University of Bonn. Respondents were presented either with a picture of an auditorium with students sitting in a class, a picture of leisure activities on campus, or no picture, respectively. To control for position effects, pictures were placed either in the upper right or upper left of the questionnaire. The results indicate that header images attract attention in the beginning of a survey, but do not significantly increase motivation over the course of the survey. When faced with a header picture, respondents in the picture conditions evaluate their time in class differently compared to respondents in the control group. While the device providing the visibility makes no difference, effects are only significant when the picture is placed on the left side of the screen. In sum, the interaction of header placement and the content-related proximity of header content and question may alter response behavior.","2020","2022-01-08 12:52:54","2022-01-08 12:52:54","","43-53","","1","14","","","","","","","","","","","","","","","","","","","","","EXPOSURE; web surveys; Context effects; device effects; header images; SURVEY PARTICIPATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M4U7EUWX","journalArticle","2017","Antoun, Christopher; Couper, Mick P.; Conrad, Frederick G.","EFFECTS OF MOBILE VERSUS PC WEB ON SURVEY RESPONSE QUALITY: A CROSSOVER EXPERIMENT IN A PROBABILITY WEB PANEL.","Public Opinion Quarterly","","","","","Survey participants are increasingly responding to Web surveys on their smartphones as opposed to their personal computers (PCs), and this change brings with it some potential data-quality issues. This study reports on a randomized crossover experiment to compare the effect of two different devices, smartphones and PCs, on response quality in a Web survey conducted in a probability-based panel. Participants (n = 1,390) were invited to complete an online questionnaire on both a smartphone (mobile Web) and PC (PC Web) in sequence. We hypothesized that smartphone use would result in lower-quality responses because people are more likely to use smartphones while multitasking or while around other people and because they could have difficulty recording their answers using a small touchscreen. While we found that respondents who participated in this study were more likely to multitask and more likely to be around other people when using smartphones, these factors had little impact on data quality. Respondents were at least as likely to provide conscientious and thoughtful answers and to disclose sensitive information on smartphones as on PCs. When using smartphones, however, respondents seemed to have trouble accurately moving a small-sized slider handle and a date-picker wheel to the intended values. Overall, we find that people using smartphones can provide high-quality responses, even when their context is more distracting, as long as they are presented with question formats that are easy to use on small touchscreens. [ABSTRACT FROM AUTHOR]","2017","2022-01-08 12:52:54","2022-01-08 12:52:54","","280-306","","S1","81","","","","","","","","","","","","","","","","","","","","","Respondents; Smartphones; Data quality; INTERNET; COMPUTER; Personal computers; Internet surveys; Probability theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WGH86AB2","journalArticle","2015","Arn, Birgit; Klug, Stefan; Kolodziejski, Janusz","Evaluation of an adapted design in a multi-device online panel: a DemoSCOPE case study","methods, data, analyses","","","","","""In this paper, we look at the challenge of optimizing survey layout in online research to enable multi-device use. Several studies provide useful advice on target-oriented implementation of web design for CAWI surveys. This paper presents results of the implementation of a new adapted design at the panel of DemoSCOPE that allows the participants to take part in a survey on multiple (especially mobile) devices. To evaluate this adapted design, we compare interview data and question timing of panellists who participated in an insurance study before and after the design transition. Central key figures concerning the completion rate, item non-response, open questions, straightlining, timing of single questions and the length of the total interview are presented. In addition, we have presented examples of both old and new design to the community and invited them to assess these examples concerning orientation, color, design and usability. We evaluate the differences in these assessments before and after the design transition for smartphone and desktop users. We end with suggestions for best practice for online studies on different devices."" (author's abstract)","2015","2022-01-08 12:52:54","2022-01-08 12:52:54","","185-212","","2","9","","","","","","","","","","","","","","","","","","","","","survey research; Umfrageforschung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y95MXZX6","journalArticle","2019","Lee, Hana; Kim, Sunwoong; Couper, Mick P.; Woo, Youngje","Experimental comparison of PC web, smartphone web, and telephone surveys in the new technology era","Social Science Computer Review","","","10.1177/0894439318756867","http://www.redi-bw.de/db/ebsco.php/search.ebscohost.com/login.aspx%3fdirect%3dtrue%26db%3dpsyh%26AN%3d2019-13380-006%26site%3dehost-live","Smartphones have become very popular globally, and smartphone ownership has overtaken conventional cell phone ownership in many countries in recent years. With this rapid rise in smartphone penetration, researchers are looking at ways to conduct web surveys using smartphones. This is particularly true of student populations where smartphone penetration is very high and web surveys are already the norm. However, researchers are raising concerns about selection biases and measurement differences between PC and smartphone respondents. Questions also remain about comparisons to traditional interviewer-administered approaches. We designed an experimental comparison between a PC web survey, a smartphone web survey and a computer-assisted telephone interviewing (CATI) survey. This study was conducted using an annual survey of students at a large university in South Korea. The CATI (interviewer-administered) survey had a higher response rate, lower margins of error, and better representation of the student population than the two web (self-administered) modes, but at a higher cost. The CATI survey also had lower rates of item nonresponse. More significant differences were found between the modes for sensitive questions than for nonsensitive ones. This suggests that CATI surveys may still have a role to play in surveys of college students, even in a country with high rates of mobile technology adoption. (PsycINFO Database Record (c) 2019 APA, all rights reserved)","2019","2022-01-08 12:52:54","2022-01-08 12:52:54","","234-247","","2","37","","","","","","","","","","","","","","","","","","","","","Smartphones; telephone survey; coverage; Computers; Online Surveys; College Students; response rate; measurement error; completion times; Error of Measurement; item nonresponse; smartphone survey; survey costs; Telephone Surveys; Test Administration; web survey; FACE-TO-FACE; SENSITIVE TOPICS; ALCOHOL; MODE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTKDU9U5","conferencePaper","2017","Wang, Lin; Antoun, Christopher; Sanders, Russell; Nichols, Elizabeth; Hawala, Erica L.; Falcone, Brian; Figueroa, Ivonne J.; Katz, Jonathan","Experimentation for developing evidence-based ui standards of mobile survey questionnaires","","978-1-4503-4656-6","","10.1145/3027063.3053181","http://dx.doi.org/10.1145/3027063.3053181","With the growing use of smartphones, many surveys can now be administered using those phones. Such questionnaires are called mobile survey questionnaires. The designer of a mobile survey questionnaire is challenged with presenting text and controls on a small display, while allowing respondents to correctly understand and answer questions with ease. To address this challenge, we are developing an evidencebased framework of user interface design for mobile survey questionnaires. The framework includes two parts: standards for the basic elements of surveyrelevant mobile device operation and guidelines for the building blocks of mobile survey questionnaires. In this presentation, we will describe five behavioral experiments designed to collect evidence for developing the standards. These experiments cover visual perception and motor actions relevant to survey completion. Some preliminary results from ongoing data collection are presented.","2017-05","2022-01-08 12:52:54","2022-01-08 12:52:54","","2998-3004","","","Part F127655","","","","","","","","Association for Computing Machinery","New York","","","","","","","","","","","","Framework; Standards; Usability; Mobile survey; Usability ACM Classification Keywords H52 User Interfaces: Human Factors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems","","","","","","","","","","","","","","",""
"C3XWNPUC","journalArticle","2010","Peytchev, Andy; Hill, Craig A.","Experiments in Mobile Web Survey Design: Similarities to Other Modes and Unique Considerations","Social Science Computer Review","","","10.1177/0894439309353037","https://doi.org/10.1177/0894439309353037","Self-administered surveys can be conducted on mobile web-capable devices, yet these devices have unique features that can affect response processes. Ninety-two adults were randomly selected and provided with mobile devices to complete weekly web surveys. Experiments were designed to address three main objectives. First, the authors test fundamental findings which have been found robust across other modes, but whose impact may be diminished in mobile web surveys (due largely to the device), by manipulating question order and scale frequencies. Second, the authors test findings from experiments in computer-administered web surveys, altering the presentation of images and the number of questions per page. Third, the authors experiment with the unique display, navigation, and input methods, through the need to scroll, the vertical versus horizontal orientation of scales, and the willingness to provide open-ended responses. Although most findings from other modes are upheld, the small screen and keyboard introduce undesirable differences in responses.","2010","2022-01-08 12:52:54","2022-01-08 12:52:54","","319-335","","3","28","","","","","","","","","","","","","","","","","","","","","Data collection; Internet; Smartphones; Education--Computer Applications; smartphones; Polls & surveys; mobile devices; Surveys; mobile web surveys; cell phones; CONTEXT; QUESTIONS; Product design; DATA-COLLECTION; computer methods, media, & applications; survey design; SCREEN SIZE; 0188: methodology and research technology; article; mobile devices cell phones smartphones survey design mobile web surveys; Personal digital assistants","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DU9FQGFS","journalArticle","2015","Gummer, Tobias; Roßmann, Joss","Explaining Interview Duration in Web Surveys: A Multilevel Approach","Social Science Computer Review","","","10.1177/0894439314533479","https://doi.org/10.1177/0894439314533479","Interview duration is an important variable in web surveys because it is a direct measure of the response burden. In this article, we analyze the effects of the survey design, respondent characteristics, and the interaction between these effects on interview duration. For that purpose, we applied multilevel analysis to a data set of 21 web surveys on political attitudes and behavior. Our results showed that factors on both levels, the individual and the survey level, had effects on interview duration. However, the larger share of the variation in interview duration is explained by the characteristics of the respondents. In this respect, we illustrate the impact of mobile devices and panel recruitment on interview duration. In addition, we found important relationships between the respondents? attitudes and how a web survey is designed: Highly motivated respondents spent significantly more time answering cognitively demanding questions than less motivated respondents. When planning a survey, not only the number and formats of questions need to be taken into account but also the expected sample composition and how the participants will respond to the design of the web survey.","2015","2022-01-08 12:52:54","2022-01-08 12:52:54","","217-234","","2","33","","","","","","","","","","","","","","","","","","","","","Data analysis; Web services; Research methodology; Internet; Education--Computer Applications; mobile devices; Mobile Phones; Interviews; Political Attitudes; AGE; EXPERIENCE; DESIGN; interview duration; multilevel analysis; online panels; web survey design; DATA QUALITY; INDICATORS; LENGTH; RESPONSE-TIMES; Political behavior; BURDEN; ORDER; SURVEY QUESTIONS; Attitude surveys","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYFWVQ2D","journalArticle","2021","Krebs, Dagmar; Höhne, Jan K.","EXPLORING SCALE DIRECTION EFFECTS AND RESPONSE BEHAVIOR ACROSS PC AND SMARTPHONE SURVEYS","Journal of Survey Statistics and Methodology","","","10.1093/jssam/smz058","","The effects of scale direction on response behavior are well known in the survey literature, where a variety of theoretical approaches are discussed, and mixed empirical findings are reported. In addition, different types of survey completion devices seem to vary in their susceptibility to scale direction effects. In this study, we therefore investigate the effect of scale direction and device type on response behavior in PC and smartphone surveys. To do so, we conducted a web survey experiment in a German non-probability access panel (N=3,401) using a two-step split-ballot design with four groups that are defined by device type (PC and smartphone) and scale direction (decremental and incremental). The results reveal that both PCs and smartphones are robust against scale direction effects. The results also show that response behavior differs substantially between PCs and smartphones, indicating that the device type (PC or smartphone) matters. In particular, the findings show that the comparability of data obtained through multi-device surveys is limited.","2021","2022-01-08 12:52:54","2022-01-08 12:52:54","","477-495","","3","9","","","","","","","","","","","","","","","","","","","","","QUALITY; NEED; AGREE/DISAGREE; MOBILE WEB; TABLETS; WEB SURVEYS; MEASUREMENT INVARIANCE; ORDER; ITEM-SPECIFIC QUESTIONS; Latent means; Measurement invariance; Multi-device survey; Rating scales; Response behavior; Scale direction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M8NBESLQ","journalArticle","2021","Bucher, Hannah; Sand, Matthias","Exploring the Feasibility of Recruiting Respondents and Collecting Web Data Via Smartphone: A Case Study of Text-To-Web Recruitment for a General Population Survey in Germany","Journal of Survey Statistics and Methodology","","","10.1093/JSSAM/SMAB006","","The widespread usage of smartphones, as well as their technical features, offers many opportunities for survey research. As a result, the importance and popularity of smartphone surveys is steadily increasing. To explore the feasibility of a new text-to-web approach for surveying people directly via their smartphones, we conducted a case study in Germany in which we recruited respondents from a mobile random digit dialing sample via text messages that included a link to a web survey. We show that, although this survey approach is feasible, it is hampered by a number of issues, namely a high loss of numbers at the invitation stage, and a high rate of implicit refusals on the landing page of the survey.","2021","2022-01-08 12:52:54","2022-01-08 12:52:54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D6MJCGGJ","journalArticle","2020","Antoun, Christopher; Cernat, Alexandru","Factors Affecting Completion Times: A Comparative Analysis of Smartphone and PC Web Surveys","Social Science Computer Review","","","10.1177/0894439318823703","","This article compares the factors affecting completion times (CTs) to web survey questions when they are answered using two different devices: personal computers (PCs) and smartphones. Several studies have reported longer CTs when respondents use smartphones than PCs. This is a concern to survey researchers because longer CTs may increase respondent burden and the risk of breakoff. However, few studies have analyzed the specific reasons for the time difference. In this analysis, we analyzed timing data from 836 respondents who completed the same web survey twice, once using a smartphone and once using PC, as part of a randomized crossover experiment in the Longitudinal Internet Studies for the Social Sciences panel. The survey contained a mix of questions (single choice, numeric entry, and text entry) that were displayed on separate pages. We included both page-level and respondent-level factors that may have contributed to the time difference between devices in cross-classified multilevel models. We found that respondents took about 1.4 times longer when using smartphones than PCs. This difference was larger when a page had more than one question or required text entry. The difference was also larger among respondents who had relatively low levels of familiarity and experience using smartphones. Respondent multitasking was associated with slower CTs, regardless of the device used. Practical implications and avenues for future research are discussed.","2020","2022-01-08 12:52:54","2022-01-08 12:52:54","","477-489","","4","38","","","","","","","","","","","","","","","","","","","","","Smartphones; mobile web surveys; Computers; Online Surveys; MOBILE; response times; smartphone surveys; Reaction Time; Experimental Subjects; Testing Methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDW29UMZ","journalArticle","2013","Callegaro, Mario","From mixed-mode to multiple devices Web surveys, smartphone surveys and apps: has the respondent gone ahead of us in answering surveys?","International Journal of Market Research","","","10.2501/IJMR-2013-026","","","2013","2022-01-08 12:52:54","2022-01-08 12:52:54","","317-320","","2","55","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GECP3B6","journalArticle","2018","Mavletova, Aigul; Couper, Mick P.; Lebedev, Daniil","Grid and Item-by-Item Formats in PC and Mobile Web Surveys","Social Science Computer Review","","","10.1177/0894439317735307","https://doi.org/10.1177/0894439317735307","While grids or matrix questions are a widely used format in PC web surveys, there is no agreement on the format in mobile web surveys. We conducted a two-wave experiment in an opt in panel in Russia, varying the question format (grid format and item-by-item format) and device respondents used for survey completion (smartphone and PC). The 1,678 respondents completed the survey in the assigned conditions in the first wave and 1,079 in the second wave. Overall, we found somewhat higher measurement error in the grid format in both mobile and PC web conditions. We found almost no significant effect of the question format on test?retest correlations between the latent scores in two waves and no differences in breakoff rates between the question formats. The multigroup comparison showed some measurement equivalence between the question formats. However, the difference varied depending on the length of a scale with a longer scale producing some differences in the measurement equivalence between the conditions. The levels of straightlining were higher in the grid than in the item-by-item format. In addition, concurrent validity was lower in the grid format in both PC and mobile web conditions. Finally, subjective indicators of respondent burden showed that the grid format increased reported technical difficulties and decreased subjective evaluation of the survey.","2018","2022-01-08 12:52:54","2022-01-08 12:52:54","","647-668","","6","36","","","","","","","","","","","","","","","","","","","","","Mobile Devices; Measurement errors; Error analysis; Internet; Smartphones; Education--Computer Applications; Polls & surveys; Psychometrics; Test Validity; mobile web surveys; Online Surveys; DESIGN; web surveys; measurement error; concurrent validity; grid questions; item-by-item format; matrix questions; measurement equivalence; reliability; MEASUREMENT INVARIANCE; Format; Equivalence; Scales","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXNA79KV","journalArticle","2016","Mavletova, Aigul; Couper, Mick P.","Grouping of items in mobile web questionnaires","Field methods","","","10.1177/1525822X15595151","http://www.redi-bw.de/db/ebsco.php/search.ebscohost.com/login.aspx%3fdirect%3dtrue%26db%3dpsyh%26AN%3d2016-17809-005%26site%3dehost-live","There is some evidence that a scrolling design may reduce breakoffs in mobile web surveys compared to a paging design, but there is little empirical evidence to guide the choice of the optimal number of items per page. We investigate the effect of the number of items presented on a page on data quality in two types of questionnaires: with or without user-controlled skips. Three versions of a 30-item instrument were compared, with 5, 15, or all 30 questions presented on a page, in two different surveys, one with skips and one without. We found that displaying 30 items on a page reduced the breakoff rate by almost one-third compared to presenting five items per page in the questionnaire without skips, but the difference was not statistically significant. In both surveys with and without skips, the completion times were significantly lower in the 30-item per page condition; however, item nonresponse rates were also higher. We give some practical recommendations to guide choices while designing questionnaires for mobile web surveys. (PsycINFO Database Record (c) 2016 APA, all rights reserved)","2016","2022-01-08 12:52:54","2022-01-08 12:52:54","","170-193","","2","28","","","","","","","","","","","","","","","","","","","","","Internet; Data quality; Polls & surveys; Questionnaires; Surveys; mobile web surveys; SMARTPHONE; DESIGN; Anthropology; breakoff rates; COMPUTER; Item Analysis (Test); Online Experiments; PC; DEVICES; Test Items; 0104:methodology and research technology; research methods/tools; social anthropology; Choices; scrolling; skips; 0514:culture and social structure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJMWJ6Y5","journalArticle","2017","Bacon, Christopher; Barlas, Frances M.; Dowling, Zoe; Thomas, Randall K.","How Effective Are Emojis In Surveys Taken on Mobile Devices? Data-Quality Implications and the Potential To Improve Mobile-Survey Engagement and Experience","Journal of Advertising Research","","","10.2501/JAR-2017-053","","The Advertising Research Foundation's ongoing How Advertising Works program combines original experiments with outside research. Launched in 2015, the program intends to offer practical guidance for improving advertising effectiveness across media and across platforms. The latest investigations led by Advertising Research Foundation Executive Researcher Christopher Bacon focused on the quality of survey research on mobile devices, which consumers increasingly are using to respond to online surveys. Specifically, the authors explored the use of symbols (emojis) as an alternative to text in the design of mobile surveys to keep respondents from abandoning the survey and to improve user experience. In the pages that follow, the authors explain the historical precedent for using symbols as communication devices, the importance of mobile-survey design using symbols, and the implication for data quality and effective survey design going forward.","2017","2022-01-08 12:52:54","2022-01-08 12:52:54","","462-470","","4","57","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XI6V7RAX","journalArticle","2014","De Bruijne, Marika; Wijnant, Arnaud","Improving Response Rates and Questionnaire Design for Mobile Web Surveys","Public Opinion Quarterly","","","10.1093/poq/nfu046","https://www.proquest.com/scholarly-journals/improving-response-rates-questionnaire-design/docview/1636484190/se-2?accountid=14570","This research note presents the results of an experiment that investigated how response rates and data quality could be improved for smartphone web surveys. First, we compare how invitations by text message versus by e-mail affect response rate. Text message invitations result in a similar total response rate as e-mail invitations when considering response via all types of online devices. When considering response via smartphones only, the survey completion rate is significantly higher. The text message contact mode also leads to a faster speed of initial response. Second, we examine the response effects of several questionnaire-design choices when using smartphones: paging versus scrolling, horizontal versus vertical question layout, number of answer options, and open-ended versus closed-ended questions. According to our findings, a scrolling layout leads to a shorter completion time than a paging layout. We further suggest that caution be used with horizontal and long-answer scales as well as open-ended text answer fields in smartphone surveys.","2014","2022-01-08 12:52:54","2022-01-08 12:52:54","","951-962","","4","78","","","","","","","","","","","","","","","","","","","","","Studies; Internet; Smartphones; Polls & surveys; Questionnaires; Surveys; Research; Comparative analysis; Experiments; Response rates; ORDER; 9130:Experiment/theoretical treatment; political behavior; article; 7100:Market research; 0827: mass phenomena; Data Quality; public opinion; Choices; Research Design; Research Responses; 9121: political behavior; Electronic Mail; Political Science","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6C4KXHAE","journalArticle","2021","Revilla, Melanie; Couper, Mick P.","Improving the Use of Voice Recording in a Smartphone Survey","Social Science Computer Review","","","10.1177/0894439319888708","https://www.proquest.com/scholarly-journals/improving-use-voice-recording-smartphone-survey/docview/2607554021/se-2?accountid=14570","More and more respondents are answering web surveys using mobile devices. Mobile respondents tend to provide shorter responses to open questions than PC respondents. Using voice recording to answer open-ended questions could increase data quality and help engage groups usually underrepresented in web surveys. Revilla, Couper, Bosch, and Asensio showed that in particular the use of voice recording still presents many challenges, even if it could be a promising tool. This article reports results from a follow-up experiment in which the main goals were to (1) test whether different instructions on how to use the voice recording tool reduce technical and understanding problems, and thereby reduce item nonresponse while preserving data quality and the evaluation of the tool; (2) test whether nonresponse due to context can be reduced by using a filter question, and how this affects data quality and the tool evaluation; and (3) understand which factors affect nonresponse to open-ended questions using voice recording, and if these factors also affect data quality and the evaluation of the tool. The experiment was implemented within a smartphone web survey in Spain focused on Android devices. The results suggest that different instructions did not affect nonresponse to the open questions and had little effect on data quality for those who did answer. Introducing a filter to ensure that people were in a setting that permits voice recording seems useful. Despite efforts to reduce problems, a substantial proportion of respondents are still unwilling or unable to answer open questions using voice recording.","2021","2022-01-08 12:52:54","2022-01-08 12:52:54","","1159-1178","","6","39","","","","","","","","","","","","","","","","","","","","","Internet; Smartphones; Education--Computer Applications; smartphones; Evaluation; android; Birthdays; data quality; Data quality; Electronic devices; Emotions; mobile web survey; nonresponse; Polls & surveys; Questions; Recording; Research responses; tool evaluation; Voice; voice recording; Webs; PROBABILITY-BASED PANEL; COMPUTER; DATA QUALITY; MOBILE DEVICES; PC; WEB","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPA97AVF","journalArticle","2013","Couper, Mick P.","Is the Sky Falling?  New Technology, Changing Media, and the Future of Surveys","Survey Research Methods","","","10.18148/SRM/2013.V7I3.5751","https://ojs.ub.uni-konstanz.de/srm/article/view/5751","In this paper I review three key technology-related trends: 1) big data, 2) non-probability samples, and 3) mobile data collection.  I focus on the implications of these trends for survey research and the research profession.  With regard to big data, I review a number of concerns that need to be addressed, and argue for a balanced and careful evaluation of the role that big data can play in the future.  I argue that these developments are unlikely to replace transitional survey data collection, but will supplement surveys and expand the range of research methods.  I also argue for the need for the survey research profession to adapt to changing circumstances.","2013-12","2022-01-08 12:52:54","2022-01-08 12:52:54","","145-156","","3","7","","","","","","","","","","","","","","","","","","","","","big data; social media; mobile   surveys; non; organic data; probability surveys","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZTDZQA4I","journalArticle","2015","Lambert, Amber D.; Miller, Angie L.","Living with Smartphones: Does Completion Device Affect Survey Responses?","Research in Higher Education","","","10.1007/S11162-014-9354-7/TABLES/5","https://link.springer.com/article/10.1007/s11162-014-9354-7","With the growing reliance on tablets and smartphones for internet access, understanding the effects of completion device on online survey responses becomes increasing important. This study uses data from the Strategic National Arts Alumni Project, a multi-institution online alumni survey designed to obtain knowledge of arts education, to explore the effects of what type of device (PC, Mac, tablet, or smartphone) a respondent uses has on his/her responses. Differences by device type in the characteristics of survey respondents, survey completion, time spent responding, willingness to answer complex and open-ended questions, and lengths of open-ended responses are discussed.","2015-03","2022-01-08 12:52:54","2022-01-08 12:52:54","","166-177","","2","56","","","","","","","","","","","","","","","","","Publisher: Kluwer Academic Publishers","","","","Smartphones; Completion device; Survey response","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QUFHYXHK","journalArticle","2014","Buskirk, Trent D.; Andrus, Charles H.","Making Mobile Browser Surveys Smarter: Results from a Randomized Experiment Comparing Online Surveys Completed via Computer or Smartphone","Field methods","","","10.1177/1525822X14526146","https://doi.org/10.1177/1525822X14526146","With nearly 50% of U.S. mobile phone subscribers using smartphones, survey researchers are beginning to explore their use as a data collection tool. The Got Healthy Apps Study (GHAS) conducted a randomized experiment to compare mode effects for a survey completed via iPhone mobile browser and online via desktop/laptop computer web browser. Mode effects were assessed for three types of outcomes: randomization/recruitment, survey process/completion, and survey items. In short, the distribution of survey completion times and the distribution of the number of apps owned were significantly different across survey mode after accounting for block group. Other key mode effects outcomes (including open-ended items, slider bar questions, and missing item rates) showed no significant differences across survey mode. Some interesting qualitative findings suggest that iPhone respondents enter more characters and omit fewer items than originally thought.","2014","2022-01-08 12:52:54","2022-01-08 12:52:54","","322-342","","4","26","","","","","","","","","","","","","","","","","","","","","Methodology; Internet; survey research; Smartphones; smartphones; Computer Applications; Mobile Phones; Surveys; apps; Computers; Online Surveys; Websites; mode effects; Recruitment; article; 0514: culture and social structure; Methodology (Data Collection); smartphones survey research mode effects apps; social anthropology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPPSUJR9","journalArticle","2019","Bosch, Oriol J.; Revilla, Melanie; DeCastellarnau, Anna; Weber, Wiebke","Measurement Reliability, Validity, and Quality of Slider Versus Radio Button Scales in an Online Probability-Based Panel in Norway","Social Science Computer Review","","","10.1177/0894439317750089","https://doi.org/10.1177/0894439317750089","Little is known about the reliability and validity in web surveys, although this is crucial information to evaluate how accurate the results might be and/or to correct for measurement errors. In particular, there are few studies based on probability-based samples for web surveys, looking at web-specific response scales and considering the impact of having smartphone respondents. In this article, we start filling these gaps by estimating the measurement quality of sliders compared to radio button scales controlling for the device respondents used. We conducted therefore two multitrait?multimethod (MTMM) experiments in the Norwegian Citizen Panel (NCP), a probability-based online panel. Overall, we find that if smartphone respondents represent a nonnegligible part of the whole sample, offering the response options in form of a slider or a radio button scale leads to a quite similar measurement quality. This means that sliders could be used more often without harming the data quality. Besides, if there are no smartphone respondents, we find that sliders can also be used, but that the marker should be placed initially in the middle rather than on the left side. However, in practice, there is no need to shift from radio buttons to sliders since the quality is not highly improved by providing sliders.","2019","2022-01-08 12:52:54","2022-01-08 12:52:54","","119-132","","1","37","","","","","","","","","","","","","","","","","","","","","Measurement; Reliability; Quality; Methodology; Measurement errors; Internet; Smartphones; Education--Computer Applications; Data quality; Polls & surveys; Test Reliability; Test Validity; Online Surveys; Test Forms; web surveys; COMPUTER; MODELS; WEB SURVEYS; VISUAL ANALOG SCALES; Radio; Scales; probability-based online panel; Buttons; measurement quality; multitrait–multimethod experiment; radio buttons; reliability and validity; slider scales; multitrait-multimethod experiment; Research Quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AQDZWN9C","journalArticle","2018","DeLeeuw, Edith D.","Mixed-Mode: Past, Present, and Future","Survey Research Methods","","","10.18148/srm/2018.v12i2.7402","","Mixed-mode surveys have been around since the late 1980s. In the past thirty years, major changes in technology and society influenced and changed data collection and survey methodology. However, in those years, mixed-mode strategies remained part of the daily survey practice, although the type of mix implemented followed the changes in technology and data collection methods. In this paper, I summarize the state of the art in traditional mixed-mode surveys and discuss implications for mixed device surveys.","2018","2022-01-08 12:52:54","2022-01-08 12:52:54","","75-89","","2","12","","","","","","","","","","","","","","","","","","","","","IMPACT; mobile surveys; METAANALYSIS; prevention; SOCIAL DESIRABILITY BIAS; online surveys; FACE-TO-FACE; WEB SURVEYS; ASSOCIATION; adjustment; DESIGNS; equivalence; mode measurement effect; mode selection effect; multiple devices; multiple modes; NONRESPONSE BIAS; offline surveys; PARTICIPATION RATES; TELEPHONE SURVEYS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HPYWCUF","journalArticle","2018","Schlosser, Stephan; Mays, Anja","Mobile and Dirty: Does Using Mobile Devices Affect the Data Quality and the Response Process of Online Surveys?","Social Science Computer Review","","","10.1177/0894439317698437","https://doi.org/10.1177/0894439317698437","In this article, we present a study on the data quality and the response process of mobile online surveys using an experimental design as compared to a standard computer. We used the following indicators to measure data quality and response properties: reaction time to survey invitation, break-off rate, item nonresponse, length of responses to open-ended questions and survey transmission, processing, and completion time. With regard to completion time, we also explored the significance of the place as well as the situation in which the survey was completed, the kind of Internet connection the respondents had as well as the hardware properties of the devices used to answer the online survey. Our results suggest comparable data quality and response properties in most aspects: There were no noticeable differences between computer and mobile users as regards break-off rate, item nonresponse, and length of responses to open-ended questions, nor the place where the survey was completed. However, it took respondents in the mobile group longer to complete the survey as compared to respondents answering the online survey on their computer. In terms of the completion time, there was a significant decrease in the differences between mobile devices and PCs when respondents used technically advanced mobile devices and had access to a fast Internet connection.","2018","2022-01-08 12:52:54","2022-01-08 12:52:54","","212-230","","2","36","","","","","","","","","","","","","","","","","","","","","Technology; Mobile Devices; Studies; Internet; online survey; Education--Computer Applications; data quality; Data quality; Electronic devices; Polls & surveys; Research responses; Mobile computing; Surveys; Computers; SMARTPHONE; mobile device; Data Sets; item nonresponse; Reaction time; response time; COMPUTER; paradata; break-off rate; length of responses to open-ended questions; mode effect; reaction time to survey invitation; TIMES; Access; Research design; Completion time; WEB SURVEY; Properties (attributes)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M6LX8TYA","journalArticle","2018","Cameron, Briana; Gentleman, Robert","Mobile Apps versus Web Browsers: A Comparison of Self-administered Survey Platforms","Chance","","","","https://www.proquest.com/scholarly-journals/mobile-apps-versus-web-browsers-comparison-self/docview/2170368207/se-2?accountid=14570","Cameron and Gentleman investigate some of the responses to a series of four surveys administered on both the 23andMe website and 23andMe mobile app to understand differences between web-based and mobile-based data collection. The surveys cover a wide variety of topics, including socioeconomic status (SES), tobacco use, allergies, and caffeine intake, and were chosen because they were available to all customers on both platforms. The use of mobile applications to capture research data efficiently is a promising technique for researchers. However, with the growth of mobile-app-based data collection, the use of mobile apps as a research tool may continue to be an important complement to many of the more-traditional web-based data collection techniques.","2018","2022-01-08 12:52:54","2022-01-08 12:52:54","","29-29","","4","31","","","","","","","","","","","","","","","","","","","","","Platforms; Data collection; Statistics; Research methodology; Polls & surveys; Web sites; Applications programs; Mobile computing; Software; Websites; Collection; Caffeine; Tobacco","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"INMJDDPZ","journalArticle","2014","De Bruijne, Marika; Wijnant, Arnaud","Mobile Response in Web Panels","Social Science Computer Review","","","10.1177/0894439314525918","https://doi.org/10.1177/0894439314525918","This article investigates unintended mobile access to surveys in online, probability-based panels. We find that spontaneous tablet usage is drastically increasing in web surveys, while smartphone usage remains low. Further, we analyze the bias of respondent profiles using smartphones and tablets compared to those using computers, on the basis of several sociodemographic characteristics. Our results indicate not only that mobile web respondents differ from PC users but also that tablet users differ from smartphone users. While tablets are used for survey completion by working (young) adults, smartphones are used merely by the young. In addition, our results indicate that mobile web respondents are more progressive and describe themselves more often as pioneers or forerunners in adopting new technology, compared to PC respondents. We further discover that respondents? preferences for devices to complete surveys are clearly in line with unintended mobile response. Finally, we present a similar analysis on intended mobile response in an experiment where smartphone users were requested to complete a mobile survey. Based on these findings, testing on tablets is strongly recommended in online surveys. If the goal is to reach young respondents, enabling surveys via smartphones should be considered.","2014","2022-01-08 12:52:54","2022-01-08 12:52:54","","728-742","","6","32","","","","","","","","","","","","","","","","","","","","","Technology; Mobile Devices; Internet; Smartphones; Education--Computer Applications; Demographic Characteristics; mobile web survey; Surveys; Preferences; Computers; Websites; Bias; Demographics; respondent preference; survey error; unintended mobile response; web panel; computer methods, media, & applications; 0188: methodology and research technology; article; mobile web survey unintended mobile response survey error web panel respondent preference; Sociodemographic Characteristics; Young Adults","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J7D2F4GD","journalArticle","2014","Link, Michael W.; Murphy, Joe; Schober, Michael F.; Buskirk, Trent D.; Hunter Childs, Jennifer; Langer Tesfaye, Casey","Mobile technologies for conducting, augmenting and potentially replacing surveys","Public Opinion Quarterly","","","10.1093/POQ/NFU054","","","2014","2022-01-08 12:52:54","2022-01-08 12:52:54","","779-787","","4","78","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BE9S9EE5","journalArticle","2021","Zou, Suiwen; Tan, Karen P.; Liu, Hongbo; Li, Xiang; Chen, Ye","Mobile vs. PC: the device mode effects on tourism online survey response quality","Current Issues in Tourism","","","10.1080/13683500.2020.1797645","","Using mobile devices to complete web-based surveys is an inescapable trend. Given the growth of this medium, some researchers are concerned about whether mobile devices are a viable channel for administering self-report online surveys. Taking two online surveys respectively using the US and China samples, this study compared the responses quality between participants responding via mobile devices and via PCs. Results from both the US and China samples revealed that although mobile respondents took longer to complete surveys than PC respondents, response quality did not differ significantly between these groups. Several behaviour patterns among mobile respondents were also identified in both samples. These findings provide practical implications to optimize web-based surveys for mobile users in tourism and hospitality research.","2021","2022-01-08 12:52:54","2022-01-08 12:52:54","","1345-1357","","10","24","","","","","","","","","","","","","","","","","","","","","TECHNOLOGY; ISSUES; Mobile device; RATES; COMPUTER; Online survey; Response quality; Theory ofsatisficing; WEB SURVEY DESIGN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XDUT4MDT","journalArticle","2014","Mavletova, Aigul; Couper, Mick P.","Mobile Web Survey Design: Scrolling versus Paging, SMS versus E-mail Invitations","Journal of Survey Statistics and Methodology","","","10.1093/JSSAM/SMU015","https://academic.oup.com/jssam/article/2/4/498/2937094","There is some evidence that questionnaire design (scrolling or paging) and invitation mode (SMS or e-mail) have an impact on response rates in web surveys completed on personal computers (PCs). This paper examines whether these findings can be generalized to mobile web surveys. First, we explore the effect of scrolling versus paging design on the breakoff rate, item nonresponse, and completion time in mobile web surveys. Second, we investigate which type of invitation and reminder mode (SMS or e-mail) is more effective in terms of producing higher participation rates and maximizing the percentage of respondents who complete the survey via a mobile device rather than a PC. The paper summarizes the results of an experiment conducted among members of a volunteer online access panel in Russia, who were asked to complete the survey using a mobile device. We find that the scrolling design leads to significantly faster completion times, lower (though not significantly lower) breakoff rates, fewer technical problems, and higher subjective ratings of the questionnaire. We also find that SMS invitations are more effective than e-mail invitations in mobile web surveys.","2014-12","2022-01-08 12:52:54","2022-01-08 12:52:54","","498-518","","4","2","","","","","","","","","","","","","","","","","Publisher: Oxford Academic","","","","Nonresponse; Mobile web surveys; Invitation mode; Participation rates; Survey design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CDZUZ23W","journalArticle","2018","Toepoel, Vera; Lugtig, Peter","Modularization in an Era of Mobile Web: Investigating the Effects of Cutting a Survey Into Smaller Pieces on Data Quality","Social Science Computer Review","","","10.1177/0894439318784882","https://journals.sagepub.com/doi/full/10.1177/0894439318784882","With the rise of mobile surveys comes the need for shorter questionnaires. We investigate the modularization of an existing questionnaire in the Longitudinal Internet Study for the Social Sciences ...","2018-07","2022-01-08 12:52:54","2022-01-08 12:52:54","","","","","","","","","","","","","","","","","","","","","","Publisher: SAGE PublicationsSage CA: Los Angeles, CA","","","","data quality; mobile surveys; online surveys; data chunking; data modularization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJKRNWXG","journalArticle","2020","Höhne, Jan K.; Revilla, Melanie; Schlosser, Stephan","Motion instructions in surveys: Compliance, acceleration, and response quality","International Journal of Market Research","","","10.1177/1470785319858587","","The increased use of smartphones in web survey responding did not only raise new research questions but also fostered new ways to research survey completion behavior. Smartphones have many built-in sensors, such as accelerometers that measure acceleration (i.e., the rate of change of velocity of an object over time). Sensor data establish new research opportunities by providing information about physical completion conditions that, for instance, can affect response quality. In this study, we explore three research questions: (1) To what extent do respondents accept to comply with motion instructions? (2) What variables affect the acceleration of smartphones? (3) Do different motion levels affect response quality? We conducted a smartphone web survey experiment using the Netquest opt-in panel in Spain and asked respondents to stand at a fix point or walk around while answering five single questions. The results reveal high compliance with motion instructions, with compliance being higher in the standing than in the walking condition. We also discovered that several variables, such as the presence of third parties, increase the acceleration of smartphones. However, the quality of responses to the five single questions did not differ significantly between the motion conditions, a finding that is in line with previous research. Our findings provide new insights into how compliance changes with motion tasks and suggest that the collection of acceleration data is a feasible and fruitful way to explore survey completion behavior. The findings also indicate that refined research on the connection between motion levels and response quality is necessary.","2020","2022-01-08 12:52:54","2022-01-08 12:52:54","","43-57","","1","62","","","","","","","","","","","","","","","","","","","","","smartphones; response quality; web survey; QUESTIONS; MOBILE DEVICES; PC; accelerometer; compliance; FORMATS; survey completion behavior; SurveyMotion; TIMES; WEB SURVEYS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SECBESVC","journalArticle","2020","Daikeler, Jessica; Bach, Ruben L.; Silber, Henning; Eckman, Stephanie","Motivated Misreporting in Smartphone Surveys","Social Science Computer Review","","","10.1177/0894439319900936","https://doi.org/10.1177/0894439319900936","Filter questions are used to administer follow-up questions to eligible respondents while allowing respondents who are not eligible to skip those questions. Filter questions can be asked in either the interleafed or the grouped formats. In the interleafed format, the follow-ups are asked immediately after the filter question; in the grouped format, follow-ups are asked after the filter question block. Underreporting can occur in the interleafed format due to respondents? desire to reduce the burden of the survey. This phenomenon is called motivated misreporting. Because smartphone surveys are more burdensome than web surveys completed on a computer or laptop, due to the smaller screen size, longer page loading times, and more distraction, we expect that motivated misreporting is more pronounced on smartphones. Furthermore, we expect that misreporting occurs not only in the filter questions themselves but also extends to data quality in the follow-up questions. We randomly assigned 3,517 respondents of a German online access panel to either the PC or the smartphone. Our results show that while both PC and smartphone respondents trigger fewer filter questions in the interleafed format than the grouped format, we did not find differences between PC and smartphone respondents regarding the number of triggered filter questions. However, smartphone respondents provide lower data quality in the follow-up questions, especially in the grouped format. We conclude with recommendations for web survey designers who intend to incorporate smartphone respondents in their surveys.","2020","2022-01-08 12:52:54","2022-01-08 12:52:54","","0894439319900936-0894439319900936","","","","","","","","","","","","","","","","","","","","","","","","measurement error; DATA QUALITY; MOBILE WEB; PC; DEVICES; filter questions; FILTER QUESTIONS; follow-up questions; misreporting; mobile data quality; motivated underreporting; TABLETS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BN86JZG6","journalArticle","2015","Toepoel, Vera; Lugtig, Peter","Online surveys are mixed-device surveys: issues associated with the use of different (mobile) devices in web surveys","methods, data, analyses","","","","https://www.wiso-net.de/document/MDA__45668","","2015","2022-01-08 12:52:54","2022-01-08 12:52:54","","155-162","","2","9","","","","","","","","","","","","","","","","","","","","","Antwortverhalten; response behavior","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QENV5DC","journalArticle","2016","Revilla, Melanie; Ochoa, Carlos","Open narrative questions in PC and smartphones: is the device playing a role?","Quality & Quantity","","","10.1007/s11135-015-0273-2","https://www.proquest.com/scholarly-journals/open-narrative-questions-pc-smartphones-is-device/docview/1827074964/se-2?accountid=14570","Most survey questions are closed questions, where respondents have to select an answer from a proposed set of alternatives. However, a lot of surveys also include, at least occasionally, some open questions. Open questions that call for elaborated and developed answers, called ""open narrative questions"", are used when the researchers want to go deeper into what the respondents think. This paper compares the answers to open narrative questions when the respondent is participating in a PC survey, in a smartphone-not-optimised survey or in a smartphone-optimised survey. The experiment was carried out in Spain using data collected by the Netquest online access panel. Respondents were assigned randomly to each type of device and survey format, in two successive waves. Because respondents have to type in their answer, we expect differences between devices, linked with the size and the kind of keyboards (i.e. physical versus digital, touch-screen or not). Differences are observed between answers that come from PCs and smartphones for the response time per written character, for the number of total characters and for the use of abbreviations, but not for the non-answer and non-substantive responses. No differences are observed between optimised and not optimised versions for smartphones, except for the response time per character written.","2016","2022-01-08 12:52:54","2022-01-08 12:52:54","","2495-2513","","6","50","","","","","","","","","","","","","","","","","","","","","Data collection; Statistics; Studies; Internet; Smartphones; Telephone communications; Polls & surveys; Research responses; Questionnaires; Hypotheses; DESIGN; 33411:Computer and Peripheral Equipment Manufacturing; Spain; COMPUTER; Experiments; Response time; RESPONSES; Personal computers; Web surveys; Narratives; Keyboards; Mobile optimised questionnaires; MOBILE WEB SURVEYS; Open narrative questions; OPEN-ENDED QUESTIONS; SIZE; 0104:methodology and research technology; Analysis; Interactive computer systems; Israel; research methods/tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JVD7SGM8","conferencePaper","2018","Olmsted-Hawala, Erica; Nichols, Elizabeth; Falcone, Brian; Figueroa, Ivonne J.; Antoun, Christopher; Wang, Lin","Optimal Data Entry Designs in Mobile Web Surveys for Older Adults","","","","10.1007/978-3-319-92034-4_26","https://www.wiso-net.de/document/BEFO__20180718734-BEFO-DOMA-ITEC-ZDEE-TECU","Growing numbers of people are using their mobile phones to respond to online surveys. As a result, survey designers face the challenge of displaying questions and their response options and navigation elements on small smartphone screens in a way that encourages survey completion. The purpose of the present study was to conduct a series of systematic assessments of how older adults using smartphones interact with different user-interface features in online surveys. This paper shares results of three different experiments. Experiment 1 compares different ways of displaying choose-one response options. Experiment 2 compares different ways of displaying numeric entry boxes, specifically ones used to collect currency information (e.g., prices, costs, salaries). Experiment 3 tests whether forward and backward navigational buttons on a smartphone survey should be labeled with words (previous, next) or simply indicated with arrow icons (). Results indicate that certain features such as picker-boxes that appear at the bottom of the screen (iOS devices), fixed formatting of numeric-entry boxes, and icon navigation buttons were problematic. They either had negative impacts on performance (response times and/or accuracy) or only a small percentage of participants preferred these design features when asked to compare them to the other features.","2018-06","2022-01-08 12:52:54","2022-01-08 12:52:54","","335-335","","","10926","","","","","","","","Springer","Cham","","","","","","","","","","","","Rückmeldezeit; Online-Überwachung; Smartphone; Erwachsener; Leitfaden; älterer Mensch; Währung","","Zhou, J.; Salvendy, G.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Human Aspects of IT for the Aged Population. Acceptance, Communication and Participation. ITAP 2018. Lecture Notes in Computer Science, vol 10926.","","","","","","","","","","","","","","",""
"GRZE3AUX","journalArticle","2017","Brosnan, Kylie; Grün, Bettina; Dolnicar, Sara","PC, phone or tablet? Use, preference and completion rates for web surveys","International Journal of Market Research","","","10.2501/IJMR-2016-049","","This study investigates whether it is the case that representativity is undermined if personal computer, tablet and smartphone respondents differ in sociodemographic characteristics and display different survey completion rates. Online market research is struggling with sample representativity. The analysis of more than ten million survey invitations, as well as stated device preference information, suggests that web survey respondents who are members of online panels still mostly use their personal computers, but do express increasing interest in using smartphones and tablets. Survey completion rates do vary across devices, and device use is significantly associated with socio-demographic characteristics and length of membership on a panel. Therefore, researchers must not limit respondents to use a specific device for completing a survey as this may compromise the quality of the survey completion experience, increase non response error and negatively affect representativity.","2017","2022-01-08 12:52:54","2022-01-08 12:52:54","","35-55","","1","59","","","","","","","","","","","","","","","","","","","","","Mobile Devices; mobile devices; QUALITY; online research; Preferences; Tablet Computers; Consumer Attitudes; DESIGN; MOBILE; web surveys; METAANALYSIS; PANELS; MODES; Consumer Research; COMPARING RESPONSE RATES; MAIL SURVEYS; Consumer Surveys; completion rates; device preference; device use","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6H8ZNE24","journalArticle","2021","Toepoel, Vera; Mathon, Karlijn; Tussenbroek, Puck; Lugtig, Peter","Probing in online mixed-device surveys: Is a research messenger layout more effective than a traditional online layout, especially on mobile devices?","Bulletin of Sociological Methodology/Bulletin de Méthodologie Sociologique","","","10.1177/07591063211019953","https://doi.org/10.1177/07591063211019953","This article compares the effectiveness of a research messenger layout to a traditional online layout with regards to probing. Responses to different types of probes (explanation, elaboration and category selection probes) were examined in terms of length and quality, measured by number of characters, number of themes, and an indicator for response quality. The research messenger layout, regardless of device being used, had a negative effect on both response length, number of themes and response quality. Further, we found that in both the traditional and research messenger layout, using a mobile device negatively affects the number of characters and themes used in probed responses. We conclude that probing is most effective when a traditional survey is completed on a computer. The research messenger layout was not able to generate responses of similar quality compared to the traditional layout, regardless of device being used.","2021","2022-01-08 12:52:54","2022-01-08 12:52:54","","74-95","","1","151","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J45DL4L5","journalArticle","2019","Cernat, Alexandru; Liu, Mingna","Radio buttons in web surveys: Searching for alternatives","International Journal of Market Research","","","10.1177/1470785318813520","","Web surveys are struggling to attract and retain respondents due to high burden and competition for the users(') attention. One possible solution to this issue is the improvement of the visual design of surveys. In this article, we evaluate the impact of visual aids such as smiley faces, stars, hearts, and thumbs as alternatives to traditional radio buttons. We use an experimental design in a nonprobability online survey to investigate how the new designs compare with radio buttons and how the results might interact with device used for completion (PC vs mobile), the use of labels, the type of response scale (bipolar vs unipolar), and the number of response categories (5 vs 7 point). While we do not find big differences in response, quality and experience, there seem to be some indication that the use of smiley faces leads to worse data quality.","2019","2022-01-08 12:52:54","2022-01-08 12:52:54","","266-286","","3","61","","","","","","","","","","","","","","","","","","","","","experimental design; response scales; web surveys; DATA QUALITY; VISUAL ANALOG SCALES; gamification; mobile survey; SURVEY DESIGN; visual design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJST6GXA","journalArticle","2019","Lugtig, Peter; Toepoel, Vera; Haan, Marieke; Zandvliet, Robbert; Klein Kranenburg, Laurens","Recruiting Young and Urban Groups into a Probability-Based Online Panel by Promoting Smartphone Use","methods, data, analyses","","","","https://www.wiso-net.de/document/SSOA__63138","A sizable minority of all web surveys are nowadays completed on smartphones. People who choose a smartphone for Internet-related tasks are different from people who mainly use a PC or tablet. Smartphone use is particularly high among the young and urban. We have to make web surveys attractive for smartphone completion in order not to lose these groups of smartphone users. In this paper we study how to encourage people to complete surveys on smartphones in order to attract hard-to-reach subgroups of the population. We experimentally test new features of a survey-friendly design: we test two versions of an invitation letter to a survey, a new questionnaire lay-out, and autoforwarding. The goal of the experiment is to evaluate whether the new survey design attracts more smartphone users, leads to a better survey experience on smartphones and results in more respondents signing up to become a member of a probability-based online panel. Our results show that the invitation letter that emphasizes the possibility for smartphone completion does not yield a higher response rate than the control condition, nor do we find differences in the socio-demographic background of respondents. We do find that slightly more respondents choose a smartphone for survey completion. The changes in the layout of the questionnaire do lead to a change in survey experience on the smartphone. Smartphone respondents need 20% less time to complete the survey when the questionnaire includes autoforwarding. However, we do not find that respondents evaluate the survey better, nor are they more likely to become a member of the panel when asked at the end of the survey. We conclude with a discussion of autoforwarding in web surveys and methods to attract smartphone users to web surveys.","2019","2022-01-08 12:52:55","2022-01-08 12:52:55","","291-306","","2","13","","","","","","","","","","","","","","","","","","","","","Mobiltelefon; Datengewinnung; data capture; online survey; Online-Befragung; panel; Panel; sample; Stichprobe; survey research; Umfrageforschung; Datenqualität; data quality; cell phone","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UFA7KL85","journalArticle","2013","Mavletova, Aigul; Couper, Mick P.","Sensitive Topics in PC Web and Mobile Web Surveys: Is There a Difference?","Survey Research Methods","","","","","A large number of findings in survey research suggest that responses to sensitive questions are situational and can vary in relation to context. The methodological literature demonstrates that social desirability biases are less prevalent in self-administered surveys, particularly in Web surveys, when there is no interviewer and less risk of presenting oneself in an unfavorable light. Since there is a growing number of users of mobile Web browsers, we focused our study on the effects of different devices (PC or cell phone) in Web surveys on the respondents' willingness to report sensitive information. To reduce selection bias, we carried out a two-wave cross-over experiment using a volunteer online access-panel in Russia. Participants were asked to complete the questionnaire in both survey modes: PC and mobile Web survey. We hypothesized that features of mobile Web usage may affect response accuracy and lead to more socially desirable responses compared to the PC Web survey mode. We found significant differences in the reporting of alcohol consumption by mode, consistent with our hypothesis. But other sensitive questions did not show similar effects. We also found that the presence of familiar bystanders had an impact on the responses, while the presence of strangers did not have any significant effect in either survey mode. Contrary to expectations, we did not find evidence of a positive impact of completing the questionnaire at home and trust in data confidentiality on the level of reporting. These results could help survey practitioners to design and improve data quality in Web surveys completed on different devices.","2013","2022-01-08 12:52:55","2022-01-08 12:52:55","","191-205","","3","7","","","","","","","","","","","","","","","","","","","","","data quality; BEHAVIOR; INTERNET; DATA-COLLECTION MODE; SOCIAL DESIRABILITY BIAS; PRIVACY; mobile Web surveys; Web surveys; PAPER-AND-PENCIL; sensitive questions; ALCOHOL-CONSUMPTION; CONFIDENTIALITY CONCERNS; DRUG-USE; interview setting; perceived privacy; presence of bystanders; SELF-ADMINISTERED QUESTIONNAIRES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PFJRRSN","journalArticle","2017","Bansal, Harvir S.; Eldridge, James; Halder, Avik; Knowles, Roddy; Murray, Michael; Sehmer, Luke; Turner, David","Shorter interviews, longer surveys Optimising the survey participant experience while accommodating ever expanding client demands","International Journal of Market Research","","","10.2501/IJMR-2017-016","","This paper explores strategies on how to best balance expanding survey length with the need for concise, relevant and engaging surveys, deployed in a device agnostic format. When designing a survey we, as an industry, are often seeking a balance between competing design challenges: clients have diverse and extensive objectives, survey participants have short attention spans and an ever increasing suite of connected devices to choose from. Survey participants are voting with their feet when surveys are not compatible with the device they want to use, whether that is the smart device in their pocket or laptop they are working on, and this is very real for online panels. We are seeing increased abandon rates, with the effects of extended fieldwork times, smaller pools of sample to draw from and the possibility of introducing bias into our data. Having spent much of 2015 working with clients to design more smart-device friendly surveys, Research Now has explored innovative ways to shorten survey length without compromising on the amount of material covered. Following on from work by Johnson et al. (2014), Research Now conducted a piece of primary research exploring survey modularisation as discussed in the current paper. The approach splits questionnaires into modules, with participants receiving only a specific module, a subset of the overall survey. It is expected that a long questionnaire can be split and when applied appropriately, designed properly and implemented effectively data can yield results comparable with a full non-modular survey. Building on previous industry work on this topic, and primary research conducted by Research Now, we discuss our methodology, the results and conclusions from this work, and explore opportunities to automate the approach. The overall goal of this study and resulting paper is to explore how adapting survey research in this way improves rather than complicates the lives of both researchers and research participants. If we are not able to shorten our surveys, then survey modularisation may prove to be our best hope for a complete, representative dataset and we need to ensure that this is achieved accurately, confidently and efficiently at scale.","2017","2022-01-08 12:52:55","2022-01-08 12:52:55","","221-238","","2","59","","","","","","","","","","","","","","","","","","","","","DESIGN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VBNFUSI","journalArticle","2019","Antoun, Christopher; Conrad, Frederick G.; Couper, Mick P.; West, Brady T.","Simultaneous estimation of multiple sources of error in a smartphone-based survey","Journal of Survey Statistics and Methodology","","","10.1093/JSSAM/SMY002","","Although web surveys in which respondents are encouraged to use smartphones have started to emerge, it is still unclear whether they are a promising alternative to traditional web surveys in which most respondents use desktop computers. For sample members to participate in smartphone-based surveys, they need to have access to a smartphone and agree to use it to complete the survey; this raises concerns about coverage and nonresponse, as well as measurement if those who agree to participate have any difficulty using smartphones. In an analysis of data from a smartphone versus desktop (within-subjects) experiment conducted in a probability-based web panel, we compare estimates produced by the smartphone web survey (one condition) and PC web survey (other condition). We estimate mode effects and then examine the extent to which these effects are attributable to coverage, nonresponse, and measurement errors in the smartphone-based survey. While mode effects were generally small, we find that the smartphone web survey produced biased estimates relative to PC web for a subset of survey variables. This was largely due to noncoverage and, to a lesser extent, nonresponse. We find no evidence of measurement effects. Our findings point to the trade-off of the advanced data collection opportunities of smartphones and the potential selection errors that such devices may introduce.","2019","2022-01-08 12:52:55","2022-01-08 12:52:55","","93-117","","1","7","","","","","","","","","","","","","","","","","","","","","QUALITY; BIAS; PC WEB; COMPUTER; SENSITIVE TOPICS; SELECTION; MOBILE WEB SURVEYS; Coverage error; Measurement error; Mobile web survey; Nonresponse error; Total survey error","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LEHK8WFL","journalArticle","2021","Maineri, Angelica M.; Bison, Ivano; Luijkx, Ruud","Slider Bars in Multi-Device Web Surveys","Social Science Computer Review","","","10.1177/0894439319879132","https://doi.org/10.1177/0894439319879132","This study explores some features of slider bars in the context of a multi-device web survey. Using data collected among the students of the University of Trento in 2015 and 2016 by means of two web surveys (N = 6,343 and 4,124) including two experiments, we investigated the effect of the initial position of the handle and the presence of numeric labels on answers provided using slider bars. It emerged that the initial position of the handle affected answers and that the number of rounded scores increased with numeric feedback. Smartphone respondents appeared more sensitive to the initial position of the handle but also less affected by the presence of numeric labels resulting in a lower tendency to rounding. Yet, outcomes on anchoring were inconclusive. Overall, no relevant differences have been detected between tablet and PC respondents. Understanding to what extent interactive and engaging tools such as slider bars can be successfully employed in multi-device surveys without affecting data quality is a key challenge for those who want to exploit the potential of web-based and multi-device data collection without undermining the quality of measurement.","2021","2022-01-08 12:52:55","2022-01-08 12:52:55","","573-591","","4","39","","","","","","","","","","","","","","","","","","","","","College students; Data collection; Internet; Education--Computer Applications; Data quality; Polls & surveys; SMARTPHONE; mobile surveys; DESIGN; MOBILE; web surveys; Bars; Labels; multi-device surveys; Rounding; slider question; sliders; survey experiment; COMPUTER; DATA QUALITY; FORMATS; RADIO BUTTON SCALES; RELIABILITY; VISUAL ANALOG SCALES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CMAMMVD9","journalArticle","2018","Toepoel, Vera; Funke, Frederik","Sliders, visual analogue scales, or buttons: Influence of formats and scales in mobile and desktop surveys","Mathematical Population Studies","","","10.1080/08898480.2018.1439245","","In an experiment dealing with the use of personal computer, tablet, or mobile, scale points (up to 5, 7, or 11) and response formats (bars or buttons) are varied to examine differences in mean scores and nonresponse. The total number of not applicable answers does not vary significantly. Personal computer has the lowest item nonresponse, followed by mobile and tablet, and a lower mean score than for mobile. Slider bars showed lower mean scores and more nonresponses than buttons, indicating that they are more prone to bias and difficult in use. Sider bars, which work with a drag-and-drop principle, perform worse than visual analogue scales working with a point-and-click principle and buttons. Five-point scales have more nonresponses than eleven-point scales. Respondents evaluate 11-point scales more positively than shorter scales.","2018","2022-01-08 12:52:55","2022-01-08 12:52:55","","112-122","","2","25","","","","","","","","","","","","","","","","","","","","","visual analogue scales; mobile surveys; DESIGN; WEB SURVEYS; RELIABILITY; questionnaire design; OPTIMAL NUMBER; RATING-SCALES; Likert scale; POINTS; response formats; slider bars","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D3UMU6R3","journalArticle","2019","Skeie, Magnus A.; Lindhjem, Henrik; Skjeflo, Sofie; Navrud, Ståle","Smartphone and tablet effects in contingent valuation web surveys - No reason to worry?","Ecological Economics","","","10.1016/j.ecolecon.2019.106390","","Stated preference (SP) web surveys are increasingly completed on mobile devices such as smartphones and tablets instead of computers. Due to differences in technical attributes and response contexts of the devices, this trend may affect the quality of the survey data and elicited welfare measures. Little is known of such device effects in SP research. In the first such study of its kind, we compare willingness to pay (WTP) and response quality between devices in a large, national contingent valuation survey. Propensity score matching is used to distinguish device effects from observed sample composition effects due to self-selection. We find significantly higher WTP for smartphone respondents in the first out of four sequential WTP questions, and no differences for tablets. Concerning data (response) quality, results are mixed, but not consistently lower for smartphones and tablets compared to computers. Measured by indicators of response randomness, shares of don't know and protest zeros, smartphone responses even show signs of higher quality. Only in terms of the extent of internal scope sensitivity, do smartphones and tablets fare somewhat worse than computers. Overall, our results do not indicate substantial loss of response quality or differences in welfare measures for mobile devices.","2019","2022-01-08 12:52:55","2022-01-08 12:52:55","","","","","165","","","","","","","","","","","","","","","","","","","","","Mobiltelefon; Ökosystem; IMPACT; QUALITY; Personal Computer; INTERNET; Umweltökonomik; Zahlungsbereitschaftsanalyse; Mobile device; MOBILE DEVICES; Contingent valuation; Ecosystem services; MAIL; MODES; Propensity score matching; SCOPE; STATED-PREFERENCE SURVEYS; Survey quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZQC48X2","journalArticle","2016","Toninelli, Daniele; Revilla, Melanie","Smartphones vs PCs: Does the Device Affect the Web Survey Experience and the Measurement Error for Sensitive Topics? A Replication of the Mavletova & Couper's 2013 Experiment","Survey Research Methods","","","10.18148/srm/2016.v1012.6274","","More and more respondents use mobile devices to complete web surveys. These devices have different characteristics, if compared to PCs (e.g. smaller screen sizes and higher portability). These characteristics can affect the survey responses, mostly when a questionnaire includes sensitive questions. This topic was already studied by Mavletova and Couper (2013), through a two-wave experiment comparing PCs and mobile devices results for the same respondents in a Russian opt-in panel. We replicated this cross-over design, focusing on an opt-in panel for Spain, involving 1,800 panellists and comparing PCs and smartphones. Our results support most of Mavletova and Couper's (2013) findings (e.g. generally the used device does not significantly affect the reporting of sensitive information), confirming their robustness over the two studied countries. For other results (e.g. trust in data confidentiality), we found differences that can be justified by the diverse context/culture or by the quick changes that are still characterizing the mobile web survey participation.","2016","2022-01-08 12:52:55","2022-01-08 12:52:55","","153-169","","2","10","","","","","","","","","","","","","","","","","","","","","smartphones; BIAS; measurement error; COMPUTERS; MODE; NONRESPONSE; Web surveys; SCREEN SIZE; mobile participation; sensitive questions; survey optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAVGR2VU","journalArticle","2019","Höhne, Jan K.; Schlosser, Stephan","SurveyMotion: what can we learn from sensor data about respondents' completion and response behavior in mobile web surveys?","International Journal of Social Research Methodology","","","10.1080/13645579.2018.1550279","https://www.proquest.com/scholarly-journals/surveymotion-what-can-we-learn-sensor-data-about/docview/2220295195/se-2?accountid=14570","Participation in web surveys via smartphones increased continuously in recent years. The reasons for this increase are a growing proportion of smartphone owners and an increase in mobile Internet access. However, research has shown that smartphone respondents are frequently distracted and/or multitasking, which might affect completion and response behavior in a negative way. We propose 'SurveyMotion (SMotion)', a JavaScript-based tool for mobile devices that can gather information about respondents' motions during web survey completion by using sensor data. Specifically, we collect data about the total acceleration (TA) of smartphones. We conducted a lab experiment and varied the form of survey completion (e.g. standing or walking). Furthermore, we employed questions with different response formats (e.g. radio buttons and sliders) and measured response times. The results reveal that SMotion detects higher TAs of smartphones for respondents with comparatively higher motion levels. In addition, respondents' motion level affects response times and the quality of responses given. The SMotion tool promotes the exploration of how respondents complete mobile web surveys and could be employed to understand how future mobile web surveys are completed.","2019","2022-01-08 12:52:55","2022-01-08 12:52:55","","379-391","","4","22","","","","","","","","","","","","","","","","","","","","","Respondents; Smartphones; Behavior; smartphones; Telephone communications; Polls & surveys; Internet access; QUALITY; Walking; Participation; Social Sciences: Comprehensive Works; MULTITASKING; response quality; web survey; Reaction time; FORMATS; Acceleration; JavaScript; mobile sensors; passive data collection; GRIDS; PARADATA; PCS; Completion; Owners; Radio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PFFVX4VN","journalArticle","2018","Revilla, Melanie; Couper, Mick P.","Testing different rank order question layouts for PC and smartphone respondents","International Journal of Social Research Methodology","","","10.1080/13645579.2018.1471371","https://www.proquest.com/scholarly-journals/testing-different-rank-order-question-layouts-pc/docview/2113030466/se-2?accountid=14570","We studied the impact of different layouts for rank order questions on respondent effort, data quality, and substantive results among PC and smartphone respondents, in an experiment in an opt-in online panel in Spain, using an order-by-click design. We experimentally varied the device, the number of columns, and, for smartphone respondents, the position of the 'next' button in questions on trust in institutions.We found some evidence of lower data quality for smartphone users but no evidence that presenting ranking items in one column performs differently than two columns. We also find little evidence that these effects differ by the number of response options presented or the number to be ranked. The placement of the 'next' button had little effect on performance on ranking items. Overall, our findings suggest that the format and layout of order-by-click questions has little effect on data quality, regardless of device used.","2018","2022-01-08 12:52:55","2022-01-08 12:52:55","","695-712","","6","21","","","","","","","","","","","","","","","","","","","","","Internet; Respondents; Smartphones; data quality; Data quality; Layout; EXPERIENCE; Social Sciences: Comprehensive Works; VALUES; PANELS; SENSITIVE TOPICS; WEB SURVEYS; PARADATA; Web surveys; order-by-click questions; rank order questions; Ranking; smartphone optimization; RATINGS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJYV9BST","journalArticle","2020","Revilla, Melanie; Couper, Mick P.; Bosch, Oriol J.; Asensio, Marc","Testing the Use of Voice Input in a Smartphone Web Survey","Social Science Computer Review","","","10.1177/0894439318810715","https://doi.org/10.1177/0894439318810715","We implemented an experiment within a smartphone web survey to explore the feasibility of using voice input (VI) options. Based on device used, participants were randomly assigned to a treatment or control group. Respondents in the iPhone operating system (iOS) treatment group were asked to use the dictation button, in which the voice was translated automatically into text by the device. Respondents with Android devices were asked to use a VI button which recorded the voice and transmitted the audio file. Both control groups were asked to answer open-ended questions using standard text entry. We found that the use of VI still presents a number of challenges for respondents. Voice recording (Android) led to substantially higher nonresponse, whereas dictation (iOS) led to slightly higher nonresponse, relative to text input. However, completion time was significantly reduced using VI. Among those who provided an answer, when dictation was used, we found fewer valid answers and less information provided, whereas for voice recording, longer and more elaborated answers were obtained. Voice recording (Android) led to significantly lower survey evaluations, but not dictation (iOS).","2020","2022-01-08 12:52:55","2022-01-08 12:52:55","","207-224","","2","38","","","","","","","","","","","","","","","","","","","","","Internet; Smartphones; Education--Computer Applications; data quality; Polls & surveys; Recording; Research responses; Voice; voice recording; mobile web surveys; PROBABILITY-BASED PANEL; COMPUTER; QUESTIONS; dictation; MOBILE DEVICES; PC; RESPONSE QUALITY; speech-to-text; Audio data; Completion time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAVSJSE2","journalArticle","2015","Huff, Kyle C.","The comparison of mobile devices to computers for web-based assessments","Computers in Human Behavior","","","10.1016/j.chb.2015.03.008","http://www.redi-bw.de/db/ebsco.php/search.ebscohost.com/login.aspx%3fdirect%3dtrue%26db%3dpsyh%26AN%3d2015-20975-025%26site%3dehost-live","This research investigated the completing of a web-based personality assessment using smart phones and computers. Data were collected from 47 undergraduate students using a within subjects design. Results indicated that the usability and the time to complete the assessment of a web-based non-optimized questionnaire is significantly different when completed with a smart phone versus a computer. However, there were no significant differences in personality scores. (PsycInfo Database Record (c) 2020 APA, all rights reserved)","2015","2022-01-08 12:52:55","2022-01-08 12:52:55","","208-212","","","49","","","","","","","","","","","","","","","","","","","","","Mobile Phones; Computer; Computers; INTERNET; PERSONALITY; DESIGN; Personality; Usability; TESTS; Mobile assessment; Personality Measures; Time; ABILITY; EQUIVALENCE; PAPER-AND-PENCIL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TD2CW2AF","journalArticle","2009","Fuchs, Marek; Busse, Britta","The Coverage Bias of Mobile Web Surveys Across European Countries","International Journal of Internet Science","","","","","In recent years, mobile devices are increasingly considered to access the World Wide Web. Several survey research organizations are about to use this technology as a means of conducting self-administered surveys. Among other advantages it allows survey researchers to overcome the lack of random selection procedures in online surveys since it provides the opportunity to use RDD-like probability sampling of cell phone numbers. However, low penetration rates of smart phones raise concerns that the coverage bias of a mobile Web survey might in fact harm survey estimates considerably. In this paper, we report results of a simulation study on the coverage bias of the mobile Web population across European countries. Based on a subset of the Eurobarometer data we estimate the relative coverage bias of the smart phone population in contrast to the general population. Even though we observed an incline of the mobile Web penetration rates over the course of the past years, coverage biases were still considerably large for socio-demographic variables. Nevertheless, in a few European countries mobile Web coverage biases are already smaller than the coverage biases of the population with traditional landline Internet access. Adapted from the source document.","2009","2022-01-08 12:52:55","2022-01-08 12:52:55","","21-33","","1","4","","","","","","","","","","","","","","","","","","","","","data collection; Simulation; Sampling; Internet; data quality; survey; Surveys; smart phone; Bias; Access; Europe; political behavior; article; 0827: mass phenomena; public opinion; 9121: political behavior; Courses; Mobile Web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y54CNGJ6","journalArticle","2019","Mason, Robert; Huff, Kyle C.","The effect of format and device on the performance and usability of web-based questionnaires","International Journal of Social Research Methodology","","","10.1080/13645579.2018.1542150","https://www.proquest.com/scholarly-journals/effect-format-device-on-performance-usability-web/docview/2196500543/se-2?accountid=14570","This article explores the comparability of assessment tools under different format conditions. Prior studies have not considered the interaction of format and device on time to complete an assessment and have instead treated each of them separately with conflicting results. This study assesses, by linear regressions using web-based data, the performance of multiple devices under varying formats while controlling for non-device factors such as demographic information. The results of this study add to the growing literature on the equivalence among devices and formats used to collect and interpret performance in a variety of organizational settings.","2019","2022-01-08 12:52:55","2022-01-08 12:52:55","","271-280","","3","22","","","","","","","","","","","","","","","","","","","","","Internet; Evaluation; Questionnaires; questionnaire; survey; usability; DESIGN; MOBILE; Social Sciences: Comprehensive Works; Demographic aspects; Computer based; TESTS; ABILITY; COMPUTERS; EQUIVALENCE; format; Mobile; PAPER; web; Organizational effectiveness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CGP24KDL","journalArticle","2015","Struminskaya, Bella; Weyandt, Kai; Bosnjak, Michael","The effects of questionnaire completion using mobile devices on data quality: evidence from a probability-based general population panel","methods, data, analyses","","","","https://www.wiso-net.de/document/MDA__45667","""The use of mobile devices such as smartphones and tablets for survey completion is growing rapidly, raising concerns regarding data quality in general, and nonresponse and measurement error in particular. We use the data from six online waves of the GESIS Panel, a probability-based mixed-mode panel representative of the German population to study whether the responses provided using tablets or smartphones differ on indicators of measurement and nonresponse errors from responses provided via personal computers or laptops. We follow an approach chosen by Lugtig and Toepoel (2015), using the following indicators of nonresponse error: item nonresponse, providing an answer to an open question; and the following indicators of measurement error: straightlining, number of characters in open questions, choice of left-aligned options in horizontal scales, and survey duration. Moreover, we extend the scope of past research by exploring whether data quality is a function of device-type or respondent-type characteristics using multilevel models. Overall, we find that responding with mobile devices is associated with a higher likelihood of measurement discrepancies compared to PC/laptop survey completion. For smartphone survey completion, the indicators of measurement and nonresponse error tend to be higher than for tablet completion. We find that most indicators of nonresponse and measurement error used in our analysis cannot be attributed to the respondent characteristics but are rather effects of mobile devices."" (author's abstract)","2015","2022-01-08 12:52:55","2022-01-08 12:52:55","","261-292","","2","9","","","","","","","","","","","","","","","","","","","","","survey research; Umfrageforschung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4XBGN97","journalArticle","2016","Lugtig, Peter; Toepoel, Vera","The Use of PCs, Smartphones, and Tablets in a Probability-Based Panel Survey: Effects on Survey Measurement Error","Social Science Computer Review","","","10.1177/0894439315574248","https://doi.org/10.1177/0894439315574248","Respondents in an Internet panel survey can often choose which device they use to complete questionnaires: a traditional PC, laptop, tablet computer, or a smartphone. Because all these devices have different screen sizes and modes of data entry, measurement errors may differ between devices. Using data from the Dutch Longitudinal Internet Study for the Social sciences panel, we evaluate which devices respondents use over time. We study the measurement error associated with each device and show that measurement errors are larger on tablets and smartphone than on PCs. To gain insight into the causes of these differences, we study changes in measurement error over time, associated with a switch of devices over two consecutive waves of the panel. We show that within individuals, measurement errors do not change with a switch in device. Therefore, we conclude that the higher measurement error in tablets and smartphones is associated with self-selection of the sample into using a particular device.","2016","2022-01-08 12:52:55","2022-01-08 12:52:55","","78-94","","1","34","","","","","","","","","","","","","","","","","","","","","mobile phones; tablets; measurement error; mixed device; panel survey; MOBILE WEB SURVEYS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QSLZUHLL","journalArticle","2018","Zijlstra, Toon; Wijgergangs, Krisje; Hoogendoorn-Lanser, Sascha","Traditional and mobile devices in computer assisted web-interviews","Transportation Research Procedia","","","","https://www.wiso-net.de/document/BEFO__20181041493-BEFO-ZDEE","Transport studies constantly rely on surveys among travelers. Computer assisted web interview is the most popular survey mode. However, respondents complete online surveys nowadays using smartphones, tablets or traditional devices. We address three questions related to this development: how important are mobile respondents; how to deal with mobile respondents; and what is the effect of mobile response in a survey? In order to answer these questions, we used a series of information dense meta-analyses and state-of-the-art literature. Our results reveal that one out of every three respondents used a mobile device in 2016. The profile of mobile respondents adheres to the profiles of hard-to-reach candidates. Four design strategies for mixed-device surveys are identified and discussed. By taking an active approach to mixed-device surveys, multiple issues associated with mobile response can be overcome, i.e. differences in completion times and break-offs can be minimized. Mobile respondents appreciate redesigned surveys. Our results are in favor of facilitating mobile respondents with an adaptive or responsive web design in surveys.","2018","2022-01-08 12:52:55","2022-01-08 12:52:55","","184-194","","","32","","","","","","","","","","","","","","","","","","","","","Online-Überwachung; Smartphone; mobiles Gerät; Datenqualität; Mischmaschine; Mischvorrichtung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2JE38W8K","journalArticle","2021","Bosch, Oriol J.; Revilla, Melanie","Using emojis in mobile web surveys for Millennials? A study in Spain and Mexico","Quality & Quantity","","","10.1007/s11135-020-00994-8","https://www.proquest.com/scholarly-journals/using-emojis-mobile-web-surveys-millennials-study/docview/2486883703/se-2","To involve Millennials in survey participation, and obtain high-quality answers from them, survey designers may require new tools that better catch Millennials' interest and attention. One key new tool that could improve the communication and make the survey participation more attractive to young respondents are the emojis. We used data from a survey conducted among Millennials by the online fieldwork company Netquest in Spain and Mexico (n = 1614) to determine how emojis can be used in mobile web surveys, in particular in open-ended questions, and how their use can affect data quality, completion time, and survey evaluation. Overall, results show a high willingness of Millennials to use emojis in surveys (both stated and actual use) and a positive impact of encouraging Millennials to use emojis in open-ended questions on the amount of information conveyed, the completion time and the survey enjoyment.","2021","2022-01-08 12:52:55","2022-01-08 12:52:55","","39-61","","","55","","","","","","","","","","","","","","","","","","","","","Statistics; Emojis; Internet; Data quality; Polls & surveys; Participation; Millennials; Mexico; Mobile web surveys; Spain; Survey evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MKKBYXNU","journalArticle","2021","Keusch, Florian; Leonard, Mariel M.; Sajons, Christoph; Steiner, Susan","Using Smartphone Technology for Research on Refugees: Evidence from Germany","Sociological Methods & Research","","","10.1177/0049124119852377","https://doi.org/10.1177/0049124119852377","Researchers attempting to survey refugees over time face methodological issues because of the transient nature of the target population. In this article, we examine whether applying smartphone technology could alleviate these issues. We interviewed 529 refugees and afterward invited them to four follow-up mobile web surveys and to install a research app for passive mobile data collection. Our main findings are as follows: First, participation in mobile web surveys declines rapidly and is rather selective with significant coverage and nonresponse biases. Second, we do not find any factor predicting types of smartphone ownership, and only low reading proficiency is significantly correlated with app nonparticipation. However, obtaining sufficiently large samples is challenging?only 5 percent of the eligible refugees installed our app. Third, offering a 30 Euro incentive leads to a statistically insignificant increase in participation in passive mobile data collection.","2021","2022-01-08 12:52:55","2022-01-08 12:52:55","","1863-1894","","4","50","","","","","","","","","","","","","","","","","","","","","participation; Technology; Data collection; Sociology; Internet; Smartphones; smartphones; DISCLOSURE; Polls & surveys; Competence; coverage; Germany; Methodological problems; mobile web surveys; Nonresponse; Ownership; Participation; passive mobile data collection; refugees; Refugees; RISK; MOBILE WEB; HARM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JTCDAVDH","journalArticle","2017","Tourangeau, Roger; Maitland, Aaron; Rivero, Gonzalo; Sun, Hanyu; Williams, Douglas; Yan, Ting","WEB SURVEYS BY SMARTPHONE AND TABLETS EFFECTS ON SURVEY RESPONSES","Public Opinion Quarterly","","","10.1093/poq/nfx035","","With respondents increasingly completing web surveys on tablet computers and smartphones, several studies have examined the potential effects of the switch from PCs to mobile devices. The studies have looked at a range of outcomes, including completion rates, breakoffs, and item nonresponse. We carried out a field experiment that compared responses obtained by smartphones, tablets, and laptop computers, focusing on the potential effects of the different devices on measurement errors. We examined whether the differences across devices in screen size (and the related need to scroll to see the entire question or the full set of response options) might moderate the effects of response order, affect the strategy respondents used to decide which of two options was preferable, change the effect of question context, or influence the use of definitions. Our experiments were based on the principle of visual prominence-the idea that respondents are more likely to notice and consider information that is easy to see. The experiments were deliberately designed to maximize the impact of screen size on the results, since the screen size would affect the visual prominence of key information. However, like many of the prior studies examining mobile devices, although response order, context, and evaluation strategy affected the answers respondents gave, few device effects emerged.","2017","2022-01-08 12:52:55","2022-01-08 12:52:55","","896-929","","4","81","","","","","","","","","","","","","","","","","","","","","DESIGN; MOBILE; COMPUTER; SENSITIVE TOPICS; OPTIONS; PREFERENCE REVERSALS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W8TYNZD5","journalArticle","2018","Tourangeau, Roger; Sun, Hanyu; Yan, Ting; Maitland, Aaron; Rivero, Gonzalo; Williams, Douglas","Web Surveys by Smartphones and Tablets: Effects on Data Quality","Social Science Computer Review","","","10.1177/0894439317719438","https://doi.org/10.1177/0894439317719438","Does completing a web survey on a smartphone or tablet computer reduce the quality of the data obtained compared to completing the survey on a laptop computer? This is an important question, since a growing proportion of web surveys are done on smartphones and tablets. Several earlier studies have attempted to gauge the effects of the switch from personal computers to mobile devices on data quality. We carried out a field experiment in eight counties around the United States that compared responses obtained by smartphones, tablets, and laptop computers. We examined a range of data quality measures including completion times, rates of missing data, straightlining, and the reliability and validity of scale responses. A unique feature of our study design is that it minimized selection effects; we provided the randomly determined device on which respondents completed the survey after they agreed to take part. As a result, respondents may have been using a device (e.g., a smartphone) for the first time. However, like many of the prior studies examining mobile devices, we find few effects of the type of device on data quality.","2018","2022-01-08 12:52:55","2022-01-08 12:52:55","","542-556","","5","36","","","","","","","","","","","","","","","","","","","","","Internet; Smartphones; Education--Computer Applications; smartphones; Telephone communications; data quality; Data quality; Electronic devices; Polls & surveys; Research responses; mobile devices; Mobile computing; DESIGN; Tablet computers; measurement error; COMPUTER; SENSITIVE TOPICS; MOBILE DEVICES; PC; Personal computers; Missing data; Rangefinding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2TMTCKN","journalArticle","2017","Keusch, Florian; Yan, Ting","Web Versus Mobile Web: An Experimental Study of Device Effects and Self-Selection Effects","Social Science Computer Review","","","10.1177/0894439316675566","https://doi.org/10.1177/0894439316675566","Due to a rising mobile device penetration, Web surveys are increasingly accessed and completed on smartphones or tablets instead of desktop computers or laptops. Mobile Web surveys are also gaining popularity as an alternative self-administered data collection mode among survey researchers. We conducted a methodological experiment among iPhone owners and compared the participation and response behavior of three groups of respondents: iPhone owners who started and completed our survey on a desktop or laptop PC, iPhone owners who self-selected to complete the survey on an iPhone, and iPhone owners who started on a PC but were requested to switch to iPhone. We found that respondents who completed the survey on a PC were more likely to be male, to have a lower educational level, and to have more experience with Web surveys than mobile Web respondents, regardless of whether they used the iPhone voluntarily or were asked to switch from a PC to an iPhone. Overall, iPhone respondents had more missing data and took longer to complete the survey than respondents who answered the questions on a PC, but they also showed less straightlining behavior. There are only minimal device differences on survey answers obtained from PCs and iPhones.","2017","2022-01-08 12:52:55","2022-01-08 12:52:55","","751-769","","6","35","","","","","","","","","","","","","","","","","","","","","Data collection; Internet; iPhone; Smartphones; Education--Computer Applications; smartphones; data quality; Polls & surveys; QUALITY; Mobile computing; Participation; Mobile communication systems; SMARTPHONE; Tablet computers; Microcomputers; PROBABILITY-BASED PANEL; COMPUTER; response times; PC; Personal computers; ONLINE SURVEYS; break-offs; missing data; mobile Web surveys; straightlining; unintentional mobile; Web surveys; MECHANICAL TURK; Missing data; 83:Social and Behavioral Sciences (CI); Alternative approaches; Data acquisition; Educational attainment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VX5HRK6E","journalArticle","2014","Toepoel, Vera; Lugtig, Peter","What Happens if You Offer a Mobile Option to Your Web Panel? Evidence From a Probability-Based Panel of Internet Users","Social Science Computer Review","","","10.1177/0894439313510482","https://doi.org/10.1177/0894439313510482","This article reports from a pilot study that was conducted in a probability-based online panel in the Netherlands. Two parallel surveys were conducted: one in the traditional questionnaire layout of the panel and the other optimized for mobile completion with new software that uses a responsive design (optimizes the layout for the device chosen). The latter questionnaire was optimized for mobile completion, and respondents could choose whether they wanted to complete the survey on their mobile phone or on a regular desktop. Results show that a substantive number of respondents (57%) used their mobile phone for survey completion. No differences were found between mobile and desktop users with regard to break offs, item nonresponse, time to complete the survey, or response effects such as length of answers to an open-ended question and the number of responses in a check-all-that-apply question. A considerable number of respondents gave permission to record their GPS coordinates, which are helpful in defining where the survey was taken. Income, household size, and household composition were found to predict mobile completion. In addition, younger respondents, who typically form a hard-to-reach group, show higher mobile completion rates.","2014","2022-01-08 12:52:55","2022-01-08 12:52:55","","544-560","","4","32","","","","","","","","","","","","","","","","","","","","","Internet; Education--Computer Applications; Computer Software; Netherlands; Software; DESIGN; Households; MODES; panel survey; Probability; nonresponse effects; measurement effects; mobile phone survey; computer methods, media, & applications; Global positioning systems--GPS; Income; 0188: methodology and research technology; article; mobile phone survey panel survey measurement effects nonresponse effects","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ADFYSAR","journalArticle","2019","Grady, Rebecca H.; Greenspan, Rachel L.; Liu, Mingna","What Is the Best Size for Matrix-Style Questions in Online Surveys?","Social Science Computer Review","","","10.1177/0894439318773733","https://doi.org/10.1177/0894439318773733","Across two studies, we aimed to determine the row and column size in matrix-style questions that best optimizes participant experience and data quality for computer and mobile users. In Study 1 (N = 2,492), respondents completed 20 questions (comprising four short scales) presented in a matrix grid (converted to item-by-item format on mobile phones). We varied the number of rows (5, 10, or 20) and columns (3, 5, or 7) of the matrix on each page. Outcomes included both data quality (straightlining, item skip rate, and internal reliability of scales) and survey experience measures (dropout rate, rating of survey experience, and completion time). Results for row size revealed dropout rate and reported survey difficulty increased as row size increased. For column size, seven columns increased the completion time of the survey, while three columns produced lower scale reliability. There was no interaction between row and column size. The best overall size tested was a 5 ? 5 matrix. In Study 2 (N = 2,570), we tested whether the effects of row size replicated when using a single 20-item scale that crossed page breaks and found that participant survey ratings were still best in the five-row condition. These results suggest that having around five rows or potentially fewer per page, and around five columns for answer options, gives the optimal survey experience, with equal or better data quality, when using matrix-style questions in an online survey. These recommendations will help researchers gain the benefits of using matrices in their surveys with the least downsides of the format.","2019","2022-01-08 12:52:55","2022-01-08 12:52:55","","435-445","","3","37","","","","","","","","","","","","","","","","","","","","","Reliability; Internet; Education--Computer Applications; data quality; Data quality; Polls & surveys; Mobile computing; DESIGN; web survey; RESPONSES; WEB; Completion time; GRIDS; matrix format; matrix size; NUMBER; Balances (scales); Format; Matrices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ANXRPXJU","journalArticle","2015","Wells, Tom","What market researchers should know about mobile surveys","International Journal of Market Research","","","10.2501/IJMR-2015-045","","Survey completions on mobile devices have been increasing rapidly. This important shift is something market researchers should definitely consider when designing and conducting self-administered online surveys. This article briefly summarises existing research and empirical results from mobile surveys. Based on the specific findings discussed, market researchers should be better aware of what to expect when fielding surveys completed by mobile respondents, whether this is intended or not. Bringing the findings together and discussing more broadly, for online surveys, market researchers should consider consciously and deliberately accommodating both mobile and PC respondents. Thus far, the research on mobile surveys indicates that consumers want the choice and ability to take surveys when they want, where they want and on the device of their choosing. It is to be hoped that market researchers are listening and become willing to accommodate survey respondents in terms of device and, by extension, time and location.","2015","2022-01-08 12:52:55","2022-01-08 12:52:55","","521-532","","4","57","","","","","","","","","","","","","","","","","","","","","QUALITY; PC; WEB","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HIUKBLPE","journalArticle","2015","Steinbrecher, Markus; Roßmann, Joss; Blumenstiel, Jan E.","Why Do Respondents Break Off Web Surveys and Does It Matter? Results From Four Follow-up Surveys","International Journal of Public Opinion Research","","","10.1093/IJPOR/EDU025","https://academic.oup.com/ijpor/article/27/2/289/745155","","2015-06","2022-01-08 12:52:55","2022-01-08 12:52:55","","289-302","","2","27","","","","","","","","","","","","","","","","","Publisher: Oxford Academic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YUE8X2VN","journalArticle","2017","Couper, Mick P.; Peterson, Gregg J.","Why Do Web Surveys Take Longer on Smartphones?","Social Science Computer Review","","","10.1177/0894439316629932","https://doi.org/10.1177/0894439316629932","Surveys completed on mobile web devices (smartphones) have been found to take longer than surveys completed on a PC. This has been found both in surveys where respondents can choose which device they use and in surveys where respondents are randomly assigned to devices. A number of potential explanations have been offered for these findings, including (1) slower transmission over cellular or Wi-Fi networks, (2) the difficulty of reading questions and selecting responses on a small device, and (3) the increased mobility of mobile web users who have more distractions while answering web surveys. In a secondary analysis of student surveys, we find that only about one-fifth of the time difference can be accounted for by transmission time (between-page time) with the balance being within-page time differences. Using multilevel models, we explore possible page-level (question-level) and respondent-level factors that may contribute to the time difference. We find that much of the time difference can be accounted for by the additional scrolling required on mobile devices, especially for grid questions.","2017","2022-01-08 12:52:55","2022-01-08 12:52:55","","357-377","","3","35","","","","","","","","","","","","","","","","","","","","","Data collection; Internet; Respondents; Smartphones; Education--Computer Applications; Electronic devices; Polls & surveys; Web sites; QUALITY; AGE; MOBILE; web surveys; Computer software; COMPUTER; online surveys; smartphone surveys; Response time; PC; Time; PARADATA; ONLINE SURVEYS; survey completion times; RESPONSE-TIMES; 83:Social and Behavioral Sciences (CI); 0188:methodology and research technology; computer methods, media, & applications; Cellular communication; Scrolling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LL3PBWK4","journalArticle","2019","Wenz, Alexander,; Jackle, Annette; Couper, Mick P.","Willingness to use mobile technologies for data collection in a probability household panel","Survey Research Methods","","","10.18148/srm/2019.v13i1.7298","","We asked members of the Understanding Society Innovation Panel about their willingness to participate in various data collection tasks on their mobile devices. We find that stated willingness varies considerably depending on the type of activity involved: respondents are less willing to participate in tasks that involve downloading and installing an app, or where data are collected passively. Stated willingness also varies between smartphones and tablets, and between types of respondents: respondents who report higher concerns about the security of data collected with mobile technologies and those who use their devices less intensively are less willing to participate in mobile data collection tasks.","2019","2022-01-08 12:52:55","2022-01-08 12:52:55","","1-22","","1","13","","","","","","","","","","","","","","","","","","","","","ACCEPTANCE; Bluetooth; smartphone; tablet; accelerometer; GPS; app","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""